<!DOCTYPE html>
<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Prompt Engineering Tagebuch</title>
    <link rel="stylesheet" href="../assets/css/styles.css" />
    <style>
      .entry {
        border-left: 3px solid var(--accent);
        padding-left: 1rem;
        margin-bottom: 1.5rem;
      }

      .entry h3 {
        margin-top: 0;
      }
    </style>
  </head>

  <body>
    <a id="top"></a>
    <header
      data-date="30. Oktober 2025"
      data-url="https://[username].github.io/agki-pm-rhizom/prompts/"
    >
      <h1>Prompt Engineering Tagebuch</h1>
      <p class="subtitle">
        Prompting-Experimente & Reflexionen zur Arbeit mit LLMs
      </p>
      <nav>
        <a href="../index.html">Home</a>
        <a href="../about.html">Forschungsblog (theoretisch)</a>
        <a href="../posts/index.html">Forschungsblog (angewandt)</a>
        <a href="../visualisierung.html">Netzwerkvisualisierung</a>
        <span aria-current="page">Prompt Engineering Tagebuch</span>
        <a href="../glossar.html">Glossar</a>
      </nav>
    </header>

    <main>
      <article>
        <p class="meta">
          Stand: <span id="today"></span> ‚Ä¢
          <span class="pill">Prompt Engineering Tagebuch</span>
        </p>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation vom 30. Oktober 2025
          ein Prompt Engineering Tagebuch mit den wichtigsten Inhalten,
          Fortschritten und Erkenntnissen zusammenstellen? Mach es bitte nach
          diesem Muster:<br /><br />

          [HTML-Muster eingef√ºgt]
        </p>

        <section class="entry">
          <h3>Eintrag 1 ‚Äì Strukturierung des Projekts & Setup</h3>
          <p>
            Zu Beginn stand die technische und methodische Vorbereitung im
            Vordergrund. Gemeinsam mit dem LLM wurden die Anforderungen f√ºr
            GitHub, VS Code, Obsidian und Python Schritt f√ºr Schritt umgesetzt,
            um eine stabile Arbeitsumgebung f√ºr das Forschungsprojekt
            <em>‚ÄûRhizomatische Strukturen im Kulturbereich‚Äú</em> zu schaffen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Einrichtung einer vollst√§ndigen
              Projektstruktur f√ºr Datenerhebung, Analyse und Dokumentation
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Schritt-f√ºr-Schritt-Anleitung mit
              iterativen R√ºckfragen
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollst√§ndiges Setup (GitHub, GitHub
              Pages, VS Code, Obsidian, Python) funktionierte nach Anleitung
            </li>
            <li>
              <strong>Erkenntnis:</strong> Pr√§zise, sequentielle Prompts mit
              klaren Zwischenschritten verhindern technische Fehler und
              √úberforderung
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 2 ‚Äì Datengrundlage & methodische Konzeptualisierung</h3>
          <p>
            Im Dialog wurde das Forschungsvorhaben zur Erfassung rhizomatischer
            Strukturen im Kulturbereich inhaltlich und methodisch gesch√§rft. Das
            LLM half, die komplexe Beschreibung in eine klar strukturierte
            Forschungslogik zu √ºberf√ºhren.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Ableitung einer logischen, datenbasierten
              Forschungsstruktur aus heterogenen Textdaten
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Analytical prompting (Strukturierung,
              Zusammenfassung, Reorganisation)
            </li>
            <li>
              <strong>Ergebnis:</strong> Klare Trennung von Datenbasis,
              Forschungskontext, Fragestellung, Methodik und Output
            </li>
            <li>
              <strong>Erkenntnis:</strong> Gute Prompts entstehen, wenn das LLM
              nicht nur auf Inhalte, sondern auf <em>Beziehungen</em> zwischen
              Datenebenen fokussiert wird
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 3 ‚Äì Webseitenstruktur & Designfeinabstimmung</h3>
          <p>
            Im weiteren Verlauf diente das LLM als Entwicklungs- und
            Designpartner bei der Umsetzung der GitHub Pages. Dabei ging es um
            Navigation, CSS-Design, Farb- und Typografiefragen sowie
            Druckansicht. Durch iteratives Prompting konnten inkrementelle
            √Ñnderungen getestet und validiert werden.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Einheitliches, druckfreundliches Layout mit
              professionellem, aber zur√ºckhaltendem Stil
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Iterative Code-Refinement-Prompts
              (‚ÄûMach es dezenter, aber professioneller‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Einheitliches Design aller Seiten;
              Navigation und Druckansicht harmonisiert
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleinere, kontextbezogene Prompts
              (‚ÄûBehalte alles, √§ndere nur Farben‚Äú) liefern stabilere Resultate
              als gro√üe Neuschreibungen
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 4 ‚Äì Fehleranalyse & Debugging mit dem LLM</h3>
          <p>
            Mehrfach traten kleinere Probleme mit GitHub Desktop, Zeilenenden,
            CSS-Abst√§nden und relativen Links auf. Durch gezieltes Nachfragen
            und schrittweise Fehlersuche im Prompt-Dialog lie√üen sich die
            Probleme effizient l√∂sen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Fehlersuche durch dialogische
              Zusammenarbeit (Codeinterpretation durch LLM)
            </li>
            <li>
              <strong>Prompt-Typ:</strong> ‚ÄûExplain and fix‚Äú-Prompts mit
              konkreten Fehlermeldungen
            </li>
            <li>
              <strong>Ergebnis:</strong> Korrekte Navigation, funktionierende
              Druckansicht, konsistente Styles
            </li>
            <li>
              <strong>Erkenntnis:</strong> Debugging gelingt am besten, wenn
              Prompts Kontext (Dateipfade, Fehlermeldung, gew√ºnschtes Verhalten)
              explizit enthalten
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 5 ‚Äì Prompt-Reflexion</h3>
          <p>
            Die Zusammenarbeit mit dem LLM zeigte, dass technisches Prompting
            (Syntax, Fehlerbehebung) und konzeptionelles Prompting (Struktur,
            Argumentation) unterschiedliche Strategien erfordern. W√§hrend
            technische Prompts pr√§zise und schrittweise formuliert sein m√ºssen,
            profitieren konzeptuelle Prompts von Offenheit und Kontextbezug.
          </p>
          <ul>
            <li>
              <strong>Gute Strategien:</strong> Iteration, Kontext-Erhalt,
              kleine Anpassungen pro Prompt
            </li>
            <li>
              <strong>Herausforderungen:</strong> Zu viele √Ñnderungen auf
              einmal; unklare Begrenzung des Aufgabenfokus
            </li>
            <li>
              <strong>Lerneffekt:</strong> Effektives Prompting ist eine Art
              ‚ÄûDialogdesign‚Äú ‚Äì es braucht Rhythmus, Pr√§zision und Geduld
            </li>
          </ul>
        </section>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation von heute (15.
          November 2025) ein Prompt Engineering Tagebuch mit den wichtigsten
          Inhalten, Fortschritten und Erkenntnissen zusammenstellen? Mach es
          bitte nach diesem Muster und setze dabei die Liste der Eintr√§ge
          fort:<br /><br />

          [HTML-Liste der bisherigen Eintr√§ge 1‚Äì5 eingef√ºgt]<br /><br />
        </p>

        <section class="entry">
          <h3>Eintrag 6 ‚Äì Erstellung einer thematischen Basisbibliographie</h3>
          <p>
            Der Arbeitstag begann mit der Bitte um eine Bibliographie zum Thema
            ‚ÄûKultur und Digitalisierung‚Äú. Das LLM √ºbernahm die Rolle eines
            Recherche- und Strukturierungspartners und half, aus einem breiten,
            unspezifizierten Themenfeld eine verwertbare, akademische
            Literaturliste zu generieren.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Erstellung einer kuratierten
              Basisbibliographie f√ºr kleine Kulturinstitutionen, Museen und
              Vereine
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Literatur-Generierung mit
              thematischer Fokussierung
            </li>
            <li>
              <strong>Ergebnis:</strong> Relevante Kernliteratur zu
              Digitalisierung, Kulturbetrieb und digitalen Strategien wurde
              zusammengestellt
            </li>
            <li>
              <strong>Erkenntnis:</strong> Die Pr√§zisierung ‚Äûkleine Museen /
              Kulturvereine‚Äú erh√∂hte die Relevanz der Literaturqualit√§t deutlich
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 7 ‚Äì Erweiterung der Bibliographie um LLM- und KI-Aspekte
          </h3>
          <p>
            Die Literaturliste wurde anschlie√üend um KI-, LLM- und
            Digitalisierungsthemen erweitert. Ziel war, die Verbindung zwischen
            aktuellen Sprachmodellen, Digitalisierungsprozessen und
            Kulturerbe-Kontexten sichtbar zu machen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Abbildung der Schnittstelle zwischen
              K√ºnstlicher Intelligenz, LLMs und digitalen Kulturdaten
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Erg√§nzungs-Prompt (‚ÄûGibt es auch
              etwas zu LLMs?‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Einbindung neuer Literatur zu
              KI-gest√ºtzten Kulturerbesystemen, Knowledge Graphs und
              automatisierter Datenanalyse
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleine, offene Erg√§nzungsfragen
              erm√∂glichen dem LLM flexible inhaltliche Erweiterungen ohne
              Stilbruch
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 8 ‚Äì Import & Normalisierung heterogener Literaturdaten
          </h3>
          <p>
            Ein komplexer Abschnitt bestand darin, eine gro√üe, unsortierte Liste
            verschiedenster Medienformate (PDF, URL, EPUB, LNK) in ein sauberes
            Literaturformat zu √ºberf√ºhren. Das LLM fungierte hier als
            ‚ÄûParsing-Agent‚Äú und normalisierte unstrukturierte Dateinamen zu
            vollst√§ndigen Literaturangaben.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Vereinheitlichung hunderter
              Literaturangaben in APA-√§hnliche Form
            </li>
            <li>
              <strong>Prompt-Typ:</strong> ‚ÄûExtract & Normalize‚Äú-Prompting
              (Datenextraktion aus Dateinamen)
            </li>
            <li>
              <strong>Ergebnis:</strong> Erzeugung einer alphabetisch
              sortierten, medien√ºbergreifenden Literatur√ºbersicht
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM ben√∂tigt klare Regeln
              (‚ÄûOption B ‚Äì strikte Dateinamen-√úbernahme‚Äú), um nicht zu viel zu
              ‚Äûerraten‚Äú
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>Eintrag 9 ‚Äì Transformation gro√üer Literaturlisten in HTML</h3>
          <p>
            Die umfangreiche Literatur wurde in ein HTML-konformes Format
            √ºberf√ºhrt, um direkt in eine wissenschaftliche Webseite integriert
            zu werden. Die Aufgabe bestand aus Formatierung,
            Listenstrukturierung und der Korrektur von HTML-Syntaxfehlern.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Automatisierte Web-Integration einer
              komplexen Bibliographie
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Code-Transformation und
              Formatierungs-Prompt
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollst√§ndig in HTML konvertierte,
              sauber strukturierte Literaturbl√∂cke
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM ist besonders effektiv, wenn
              der Ziel-HTML-Block klar vorgegeben wird
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 10 ‚Äì Typografie & CSS-Optimierung des
            Literaturverzeichnisses
          </h3>
          <p>
            Ein zentraler Teil des Dialogs drehte sich um typografisch saubere
            APA-Darstellung: kleinere Schrift, korrektes Hanging-Indent und
            automatische Numerierung. Mehrere Iterationen f√ºhrten zu einer
            stabilen, kompakten Darstellung.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Professionelle, automatisierte
              APA-Darstellung in HTML/CSS
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Code-Refinement / Micro-Prompts
              (‚Äûetwas kleiner‚Äú, ‚Äûmehr Abstand‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollautomatische APA-Nummerierung mit
              CSS-Counter, konsistentem Hanging-Indent
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleine CSS-Prompts mit klaren
              Variablen (‚ÄûSchrift kleiner, aber lesbar‚Äú) liefern zuverl√§ssig
              pr√§zise Ergebnisse
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 11 ‚Äì Fehlerkorrektur: doppelte Nummerierung &
            Styling-Konflikte
          </h3>
          <p>
            Ein technisches Problem entstand durch doppelte Nummerierung:
            manuelle Werte wie <code>[01]</code> kollidierten mit der
            automatischen CSS-Z√§hlung. Durch Debugging im Dialog wurden die
            Konflikte aufgel√∂st.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Entfernen der doppelten Nummerierung und
              Sicherstellung funktionierender Fu√ünoten-Links
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Debugging-Prompt (‚ÄûWo muss ich das
              einf√ºgen?‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Bereinigte Liste, automatische
              Nummerierung, funktionierende IDs f√ºr Fu√ünoten
            </li>
            <li>
              <strong>Erkenntnis:</strong> Bei HTML+CSS muss das LLM klare
              Angaben erhalten, welcher Block √ºbrig bleiben soll ‚Äì sonst
              entstehen √úberschreibungsfehler
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>Eintrag 12 ‚Äì Finalisierung und typografische Feinjustierung</h3>
          <p>
            Zum Abschluss wurden Schriftgr√∂√üe, Zeilenabstand und Einz√ºge weiter
            optimiert. Das LLM passte die Literaturtypografie an
            wissenschaftliche Standards an, ohne die Lesbarkeit auf der Webseite
            zu beeintr√§chtigen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Erstellung einer minimalistisch-kompakten,
              wissenschaftlich korrekten Literaturliste
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Feintuning-Prompt (‚ÄûJa, bitte etwas
              kleiner‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Stabile Endversion der APA-Darstellung
              mit CSS-Counter, d√ºnnerem Zeilenabstand und kompakter Einr√ºckung
            </li>
            <li>
              <strong>Erkenntnis:</strong> Visuelles Feintuning gelingt am
              besten, wenn man schrittweise konkretisiert (‚Äûnoch kleiner‚Äú, ‚Äûnoch
              enger‚Äú statt ‚Äûmach sch√∂ner‚Äú)
            </li>
          </ul>
        </section>

        <p class="intro-note">
          Erst auf Aufforderung, eine Prompt-Reflexion nach dem Muster von
          Eintrag 5 zu erg√§nzen:
        </p>

        <section class="entry">
          <h3>Eintrag 13 ‚Äì Gesamtreflexion: Prompting als Arbeitsmethode</h3>
          <p>
            Der gesamte Verlauf der Zusammenarbeit zeigt sehr klar, dass
            Prompting nicht blo√ü ein technisches Werkzeug ist, sondern eine
            eigenst√§ndige Arbeitsmethode, die Struktur, Pr√§zision und
            dialogische Klarheit erfordert. √úber alle Eintr√§ge hinweg ‚Äì von
            Setup und Dateistruktur √ºber Datenvisualisierung, Literaturlisten,
            CSS-Feinjustierung, Debugging und Webdesign ‚Äì wurde deutlich, dass
            gutes Prompting weniger von formaler Komplexit√§t als von sauberem
            Kontextmanagement und iterativer Kommunikation abh√§ngt.
          </p>

          <ul>
            <li>
              <strong>Kontextpflege als Schl√ºssel:</strong> Effektive Ergebnisse
              entstanden immer dann, wenn fr√ºhere Schritte, getroffene
              Entscheidungen und relevante Codeausschnitte bewusst im Prompt
              gehalten oder wiederholend erkl√§rt wurden. Das LLM arbeitet
              optimal, wenn es an eine kontinuierliche argumentative Linie
              ankn√ºpfen kann.
            </li>

            <li>
              <strong>Kleine Schritte statt gro√üe Spr√ºnge:</strong> In fast
              allen technischen Aufgaben (HTML-Listen, automatische
              APA-Nummerierung, CSS-Refactoring, Druckansicht, Hanging-Indent,
              Typografie) zeigte sich, dass kleine, klar isolierte Anweisungen
              bessere Ergebnisse liefern als umfassende Neuformulierungen.
              Iteration schl√§gt Komplettanweisungen.
            </li>

            <li>
              <strong>Explizite Fokussierung:</strong> Das LLM reagiert
              stabiler, wenn der Aufgabenfokus eng gesetzt wird (‚Äûnur
              Schriftgr√∂√üe √§ndern‚Äú, ‚ÄûNummern automatisch, keine manuelle
              Nummerierung‚Äú, ‚Äûbehalte alles au√üer dem Abstand‚Äú). Dadurch werden
              Nebeneffekte, Stil√ºberschneidungen oder √úberinterpretationen
              vermieden.
            </li>

            <li>
              <strong>Verst√§ndnis von Beziehungen zwischen Komponenten:</strong>
              Besonders bei Webdesign und CSS half das LLM am besten, wenn die
              Prompts nicht nur Beschreibungen einzelner Elemente enthielten,
              sondern die Beziehungen zwischen Selektoren, Stilregeln und
              HTML-Struktur benannten. Prompting funktioniert als ‚ÄûSystemdenken
              in Sprache‚Äú.
            </li>

            <li>
              <strong>Reflexion verbessert das Prompting:</strong> Mehrere
              Eintr√§ge zeigten, dass die Qualit√§t der Ergebnisse steigt, wenn
              der Prompt explizit begr√ºndet, warum eine √Ñnderung vorgenommen
              wird (‚Äûweil Schrift zu gro√ü‚Äú, ‚Äûweil doppelte Nummerierung‚Äú, ‚Äûweil
              Abstand unruhig wirkt‚Äú). Diese Meta-Kommunikation erleichtert dem
              LLM, die gew√ºnschte Richtung zu verstehen.
            </li>

            <li>
              <strong>Prompting als kollaborative Wissensarbeit:</strong> Die
              gesamte Arbeit best√§tigt, dass LLM-Interaktion in
              Forschungsprojekten nicht als Werkzeugbedienung, sondern als
              kollaborativer, iterativer Denkprozess funktioniert.
              Strukturierung, Dekontextualisierung, Umformatierung und
              Designentscheidungen entstehen im wechselseitigen Dialog ‚Äì
              Prompting wird damit selbst zu einer epistemischen Praxis des
              Projekts.
            </li>
          </ul>

          <p>
            Insgesamt zeigt der gesamte Prompt-Verlauf dieses Projekttages, dass
            erfolgreiches Prompting nicht nur genaue Befehle produziert, sondern
            Denk-, Struktur- und Entscheidungsprozesse stabilisiert. Das LLM
            wird damit zum methodischen Partner, dessen Potenzial sich erst
            durch dialogische F√ºhrung voll entfaltet.
          </p>
        </section>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation von heute (16.
          November 2025) ein Prompt Engineering Tagebuch mit den wichtigsten
          Inhalten, Fortschritten und Erkenntnissen zusammenstellen? Mach es
          bitte nach diesem Muster und setze dabei die Liste der Eintr√§ge
          fort:<br /><br />

          [HTML-Liste der bisherigen Eintr√§ge eingef√ºgt]<br /><br />
        </p>

        <!-- ================================================ -->
        <!-- PROMPT ENGINEERING TAGEBUCH ‚Äì EINTR√ÑGE ab 14    -->
        <!-- ================================================ -->

        <section class="entry">
          <h3>Eintrag 14 ‚Äì HTML-Integration & strukturelle Anpassungen</h3>
          <p>
            Der Arbeitstag begann mit mehreren Iterationen rund um die
            Startseite, die About-Seite und die Einbindung von Bildern. Das LLM
            wurde eingesetzt, um HTML-Bl√∂cke umzuschreiben, redundante Inhalte
            zu reorganisieren und Navigationselemente konsistenter zu gestalten.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Straffe, klare Startseite + Verlagerung
              l√§ngerer Texte in ‚ÄûAbout‚Äú
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Strukturierungs-Prompts (‚ÄûBitte
              komplett neu formulieren‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Modularere Seitenstruktur; Startseite
              mit kurzem Intro und Bild
            </li>
            <li>
              <strong>Erkenntnis:</strong> Bei HTML-Reorganisation ist es
              entscheidend, dem LLM die Dateipfade und die gew√ºnschte
              Positionierung exakt zu nennen
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 15 ‚Äì Linkstruktur, relative Pfade & Navigationsfehler</h3>
          <p>
            Mehrere Prompts betrafen fehlerhafte Links (<code
              >./index.html</code
            >
            vs. <code>../index.html</code>) sowie die Frage, wie korrekt
            zwischen Ordnern navigiert wird. Durch Schritt-f√ºr-Schritt-Debugging
            konnte die Navigation stabilisiert werden.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Fehlerfreie relative Links zwischen
              <code>/posts/</code> und Root-Verzeichnis
            </li>
            <li>
              <strong>Prompt-Typ:</strong> ‚ÄûExplain & fix‚Äú-Prompts zur
              Pfadkorrektur
            </li>
            <li>
              <strong>Ergebnis:</strong> Alle internen Links funktionieren
              unabh√§ngig vom Ordnerkontext
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM kann nur korrekte Pfade
              generieren, wenn die exakte Ordnerstruktur im Prompt mitformuliert
              wird
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 16 ‚Äì CSS-Klassen, Bilddarstellung & responsive Design</h3>
          <p>
            Ein Schwerpunkt war die Frage, warum Bilder nicht angezeigt wurden.
            √úber mehrere Anl√§ufe wurde gekl√§rt, dass die verwendete Klasse
            <code>.hero-image</code> nicht existierte und stattdessen
            <code>.image</code> genutzt werden musste. Gleichzeitig wurde
            demonstriert, wie man Bilder kleiner, zentriert oder mit Captions
            (<code>&lt;figcaption&gt;</code>) einbindet.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Konsistente Bilddarstellung in allen
              Blog-Eintr√§gen
            </li>
            <li><strong>Prompt-Typ:</strong> CSS-Refinement-Prompts</li>
            <li>
              <strong>Ergebnis:</strong> Einheitliche Klassenstruktur
              (<code>.image</code>, <code>.image.narrow</code>) und
              funktionierende Captions
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleine CSS-Nachbesserungen durch das
              LLM funktionieren verl√§sslich, wenn HTML und CSS gemeinsam gezeigt
              werden
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 17 ‚Äì JavaScript-Optimierung & Tooltip-Feinjustierung</h3>
          <p>
            Bei der Gestaltung der Fu√ünoten-Tooltips wurden mehrere kleinere
            Optimierungen vorgenommen: Bereinigung der Positionierungslogik,
            Sicherstellen, dass <code>scrollIntoView()</code> erst nach dem
            √ñffnen von <code>&lt;details&gt;</code> l√§uft, sowie
            Vereinheitlichung der Hash-Navigation. Das LLM half, die
            Funktionsweise zu debuggen und zu erkl√§ren.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Stabiles, barrierearmes Fu√ünoten-System
            </li>
            <li>
              <strong>Prompt-Typ:</strong> JS-Debugging-Prompts (‚ÄûWarum springt
              der Tooltip?‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Deutlich stabilere Interaktion mit
              Footnotes & Literaturverzeichnis
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM ben√∂tigt beim Debuggen den
              gesamten JavaScript-Block, um Seiteneffekte korrekt einzusch√§tzen
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>
            Eintrag 18 ‚Äì Vollintegration gro√üer Textdateien (Modelltheorie)
          </h3>
          <p>
            Ein umfangreicher Abschnitt der Sitzung bestand darin, einen langen
            wissenschaftlichen Text (Stachowiaks Modelltheorie, Relation zum
            Datenmodell) in die Forschungsseite einzubetten. Das LLM √ºbernahm
            die Aufgabe, den Text HTML-konform zu strukturieren, stilistisch in
            das bestehende Layout einzuf√ºgen und Kapitel logisch einzubinden
            (‚ÄûNetzwerkmodell Teil II‚Äú).
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Wissenschaftlichen Langtext harmonisch in
              das Weblayout integrieren
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Transformations-Prompts (‚ÄûBaue das
              unter Abschnitt X ein‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> HTML-bl√∂cke mit semantisch korrekten
              √úberschriften, Listen und Abs√§tzen
            </li>
            <li>
              <strong>Erkenntnis:</strong> LLM-basierte
              Text-nach-HTML-Konvertierung gelingt besonders sauber, wenn die
              Zielstruktur (Kapitel, Unterkapitel) vorher festgelegt wird
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 19 ‚Äì Datenbankschema, ER-Diagramm & Netzwerklogik</h3>
          <p>
            Ein zentraler Teil des Dialogs drehte sich um die tats√§chliche
            Struktur der SQLite-Datenbank <code>rhizom.db</code>. Das LLM
            analysierte die Tabellen, stellte Referenzen her und formulierte
            einen pr√§zisen Netzwerkaufbau: Nodes = Personen + Projekte, Edges =
            Beziehungen √ºber Rollen und Zeit. Die Modelllogik wurde ausf√ºhrlich
            in Text umgesetzt und korrekt an die reale Datenstruktur angepasst.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Korrekte Darstellung des realen
              Datenmodells anstelle fr√ºherer Platzhalter
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Analyse-Prompt (‚ÄûSchau dir die DB
              genau an!‚Äú)
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollst√§ndig √ºberarbeiteter Abschnitt
              ‚ÄûNetzwerkmodell (Teil II)‚Äú
            </li>
            <li>
              <strong>Erkenntnis:</strong> Je pr√§ziser die Datenquelle (hier:
              echte DB), desto zuverl√§ssiger die Modellbeschreibung des LLM
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 20 ‚Äì Einbettung von PDF-Material & Download-Links</h3>
          <p>
            Es wurde gekl√§rt, wie interne Dateien ‚Äì konkret
            <code>data/rhizom_text.pdf</code> ‚Äì korrekt verlinkt werden. Das LLM
            stellte einfache, robuste HTML-Snippets bereit, um PDF-Downloads
            projektweit konsistent zu integrieren.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Korrekte Einbindung interner Downloads
            </li>
            <li><strong>Prompt-Typ:</strong> ‚ÄûShow me the snippet‚Äú-Prompt</li>
            <li>
              <strong>Ergebnis:</strong> Sauberer Download-Link mit
              <code>target="_blank"</code>
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM liefert besonders stabile
              Ergebnisse, wenn der exakte Ordnerpfad vorgegeben wird
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>
            Eintrag 21 ‚Äì Gro√ües HTML-Refactoring & Zusammenf√ºhrung mehrere
            Teilseiten
          </h3>
          <p>
            Am Ende wurden l√§ngere HTML-Passagen zusammengef√ºhrt:
            Netzwerkmodell, Modelltheorie, ER-Diagramm, visuelle Beispiele,
            Methodenabschnitte. Das LLM unterst√ºtzte beim Zusammenbau gro√üer
            HTML-Dateien und stellte sicher, dass semantische Ebenen
            (<code>&lt;section&gt;</code>, <code>&lt;h2&gt;</code>,
            <code>&lt;article&gt;</code>) erhalten bleiben.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Harmonisierung der gesamten Forschungsseite
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Gro√üformatige ‚ÄûIntegrations-Prompts‚Äú
            </li>
            <li>
              <strong>Ergebnis:</strong> Konsistentes, logisches Dokument ohne
              doppelte √úberschriften
            </li>
            <li>
              <strong>Erkenntnis:</strong> Bei sehr langen HTML-Texten
              funktioniert das LLM am besten, wenn Schritt f√ºr Schritt
              integriert und nicht alles auf einmal umgewandelt wird
            </li>
          </ul>
        </section>

        <!-- ========================= -->
        <!-- ABSCHLUSSREFLEXION       -->
        <!-- ========================= -->

        <section class="entry">
          <h3>
            Eintrag 22 ‚Äì Reflexion: Prompting als Web-Entwicklungsworkflow
          </h3>
          <p>
            Der heutige Arbeitstag hat exemplarisch gezeigt, dass Prompting beim
            Web-Development eine hybride Arbeitsform darstellt: gleichzeitig
            analytisch, technisch und kuratorisch. HTML, CSS und JavaScript
            wurden nicht einfach generiert, sondern in dialogischen Iterationen
            verbessert.
          </p>

          <ul>
            <li>
              <strong>Iterationen als Designprinzip:</strong>
              Die besten Ergebnisse entstanden immer in kleinen Schritten: ‚ÄûMach
              das Bild kleiner‚Äú, ‚ÄûNur die Klasse √§ndern, sonst nichts‚Äú, ‚ÄûBehalte
              den gesamten Block, f√ºge X ein‚Äú.
            </li>

            <li>
              <strong>Kontext entscheidet alles:</strong>
              Das LLM reagierte besonders stabil, wenn der gesamte HTML- oder
              CSS-Block gezeigt wurde, statt nur einzelne Zeilen.
            </li>

            <li>
              <strong>Prompting als kooperative Wissensarbeit:</strong>
              Komplexe Inhalte wie Datenbanken, wissenschaftliche Modelltheorie,
              Webdesign und Informationsarchitektur wurden im Wechselspiel
              zwischen Mensch und Modell erzeugt ‚Äì nicht als ‚ÄûAntwort‚Äú, sondern
              als kontinuierliches Co-Entwerfen.
            </li>

            <li>
              <strong>Fehler als Teil des Workflows:</strong>
              Linkfehler, kaputte Bilder, ungeschlossene Tags ‚Äì das Debugging
              war selbst ein Prompting-Prozess und wurde durch gemeinsame
              Fehlersuche effizient gel√∂st.
            </li>
          </ul>

          <p>
            Insgesamt zeigt der heutige Tag sehr klar: Prompt Engineering ist
            nicht nur Produktionsmittel, sondern Teil des Forschungs- und
            Entwicklungsprozesses ‚Äì ein dialogischer Lernraum, der technische
            Umsetzung, konzeptionelle Klarheit und kontinuierliches Refactoring
            miteinander verbindet.
          </p>
        </section>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation von heute (17.
          November 2025) ein Prompt Engineering Tagebuch mit den wichtigsten
          Inhalten, Fortschritten und Erkenntnissen zusammenstellen? Mach es
          bitte nach diesem Muster und setze dabei die Liste der Eintr√§ge fort
          umd beginne bitte bei diesem Promt: <br />
          GPT, ich habe folgendes Problem: Ich habe die Datei
          involved_artists_cleaned.csv in Excel ge√∂ffnet und sie als
          involved_artists_cleaned.json gespeichert, um sie danach in Gephi
          (https://lite.gephi.org/v1.0.1/) importieren zu k√∂nnen. Leider kommt
          beim Import eine Fehlermeldung: Unexpected token 'a', "art_id,art"...
          is not valid JSON. Kannst du mir bitte daraus eine JSON-Datei machen,
          die sich in Gephi importieren l√§sst? Ich schicke dir die
          Ausgangs-CSV-Datei mit.<br /><br />

          [CSV-Datei angeh√§ngt] [HTML-Muster eingef√ºgt]
        </p>

        <section class="entry">
          <h3>
            Eintrag 23 ‚Äì Datenkonvertierung, Netzwerkexport & komplexes
            Web-Debugging
          </h3>
          <p>
            Der heutige Arbeitstag konzentrierte sich auf die Transformation und
            Visualisierung der Projektdaten f√ºr das Rhizom-Netzwerk ‚Äì beginnend
            mit einer fehlerhaften CSV‚ÜíJSON-Konvertierung f√ºr Gephi und endend
            mit einer tiefgreifenden Web-Debugging-Phase, in der ein
            interaktiver Sigma.js-Graph in die GitHub-Pages-Seite integriert
            wurde.
          </p>

          <ul>
            <li>
              <strong>Ziel:</strong> Herstellung eines vollst√§ndigen Workflows
              von Rohdaten (CSV/SQLite) ‚Üí GEXF ‚Üí JSON ‚Üí interaktive
              Webvisualisierung auf GitHub Pages
            </li>

            <li>
              <strong>Prompt-Typ:</strong>
              mehrstufiges Engineering aus datenorientierten Prompts
              (‚ÄûKonvertiere diese Tabelle‚Äú), Analyse-Prompts (‚ÄûWarum l√§dt Gephi
              das nicht?‚Äú), technischen Web-Refactoring-Prompts (‚ÄûGib mir eine
              Inline-Version‚Äú) und iterativem JavaScript-Debugging.
            </li>

            <li>
              <strong>Ergebnis:</strong>
              Die CSV konnte fehlerfrei in Gephi lesbares JSON konvertiert
              werden, die SQLite-Datenbank wurde ausgelesen, ein vollst√§ndiger
              <code>rhizom_graph.json</code>-Export wurde erzeugt und ein
              funktionierender Sigma.js-Renderer in die Forschungsseite
              integriert. Mehrere Fehler (fehlende Node-Koordinaten, fehlende
              Bibliotheken, falsche relative Pfade, CORS-Limitierungen, und
              UMD-vs-ESM-Probleme) wurden systematisch gel√∂st.
            </li>

            <li>
              <strong>Erkenntnisse:</strong>
              <ul>
                <li>
                  <strong>1. Fehlerursachen m√ºssen isoliert werden.</strong>
                  JSON-Parsing-Fehler, GEXF-Attribute, fehlende
                  Node-Koordinaten, falsche JavaScript-Dateien und
                  GitHub-Pages-Filepaths k√∂nnen nur im Prompt gel√∂st werden,
                  wenn der Kontext (Fehlermeldung + Codeblock + Dateipfad)
                  vollst√§ndig angegeben wird.
                </li>

                <li>
                  <strong
                    >2. Webvisualisierung erfordert exakte
                    Pfadkontrolle.</strong
                  >
                  Viele Fehler entstanden durch relative Pfade (‚Äû./‚Äú vs ‚Äû../‚Äú),
                  die GitHub Pages anders interpretiert als VS Code Live Server.
                </li>

                <li>
                  <strong
                    >3. Sigma.js braucht g√ºltige Graph-Koordinaten.</strong
                  >
                  Der Debugging-Prozess zeigte, dass fehlende <code>x</code> und
                  <code>y</code>-Attribute jede Render-Pipeline sofort stoppen ‚Äì
                  das erzeugte den ‚Äûwei√ü-leeren Graphen‚Äú.
                </li>

                <li>
                  <strong
                    >4. LLMs eignen sich ideal f√ºr iterative
                    Web-Debugging-Prozesse.</strong
                  >
                  Die Dialogform (‚ÄûBitte nur diesen Block ersetzen‚Äú) erm√∂glichte
                  eine schrittweise Korrektur von JavaScript, HTML und JSON,
                  ohne das Gesamtprojekt jedes Mal neu aufzubauen.
                </li>

                <li>
                  <strong
                    >5. Datenattribute m√ºssen pr√§zise benannt werden.</strong
                  >
                  Die Analyse des GEXF zeigte, dass Farbcodierung, Labels,
                  Filter und Hover-Infos erst funktionieren, wenn die
                  tats√§chlichen Attributnamen aus Gephi (z. B.
                  <code>art_name</code>, <code>art_nationality</code>,
                  <code>pro_title</code>) korrekt in Sigma gemappt werden.
                </li>
              </ul>
            </li>
          </ul>

          <p>
            Insgesamt war Eintrag 23 ein Musterbeispiel f√ºr datenorientiertes
            Prompting, das zunehmend technische Komplexit√§t (Dateiformate,
            Browser-Limits, Visualisierungsbibliotheken, Datenmodelle) mit
            kreativer, iterativer Zusammenarbeit verbindet. Der Tag
            verdeutlichte einmal mehr, dass Prompt Engineering eine vollst√§ndige
            Entwicklungsumgebung ersetzen kann, wenn der Dialog strukturiert,
            kleinteilig und datenbewusst gef√ºhrt wird.
          </p>
        </section>

        <section class="entry">
          <p class="intro-note">
            Kannst du bitte einen weiteren Eintrag hinzuf√ºgen, in dem du das LLM
            - also dich selbst - reflektierst und deine Fehler analysierst? So
            hast du mehrfach Links gepostet, die nicht funktioniert haben, wie
            zum Beispiel:<br />
            1. Lade dir diese beiden Dateien herunter:<br />
            üîó Graphology (minified)<br />

            https://unpkg.com/graphology/dist/graphology.min.js<br />

            üîó Sigma.js (minified)<br />

            https://unpkg.com/sigma/build/sigma.min.js
          </p>

          <p>
            Ja, das ist eine wichtige und sehr sinnvolle Erg√§nzung.<br />
            Hier ist ein weiterer Eintrag, der genau diese Punkte thematisiert
            und deine Beobachtung mit den fehlerhaften Links (z.B. unpkg-URLs)
            explizit aufgreift.<br />

            Bitte einfach direkt nach Eintrag 23 einf√ºgen:
          </p>
          <h3>
            Eintrag 24 ‚Äì Reflexion: Grenzen des LLM & eigene Fehlleistungen
          </h3>
          <p>
            In diesem Abschnitt wurde das LLM selbst zum Gegenstand der
            Reflexion. Besonders deutlich wurden dabei Situationen, in denen das
            Modell falsche oder nicht funktionierende L√∂sungsvorschl√§ge machte ‚Äì
            etwa beim Umgang mit JavaScript-Bibliotheken (Sigma.js, Graphology)
            und externen CDN-Links.
          </p>

          <ul>
            <li>
              <strong>Ausgangspunkt:</strong> Mehrfach generierte das LLM
              Download-Links f√ºr Bibliotheken, die in der konkreten Umgebung
              nicht funktionierten oder in dieser Form gar nicht verf√ºgbar waren
              ‚Äì z.&nbsp;B.:
              <ul>
                <li>
                  <code
                    >https://unpkg.com/graphology/dist/graphology.min.js</code
                  >
                </li>
                <li><code>https://unpkg.com/sigma/build/sigma.min.js</code></li>
              </ul>
              Diese Vorschl√§ge wirkten auf den ersten Blick plausibel, waren
              aber praktisch nicht nutzbar.
            </li>

            <li>
              <strong
                >Fehlertyp 1: Halluzinierte oder verallgemeinerte Pfade.</strong
              >
              Das LLM neigt dazu, ‚Äûtypische‚Äú URL-Schemata (z.&nbsp;B. von unpkg
              oder jsDelivr) zu verallgemeinern und als konkrete L√∂sung
              auszugeben, obwohl es die aktuelle Erreichbarkeit, die genaue
              Version oder die Existenz des Pfades nicht pr√ºfen kann. F√ºr die
              Nutzer:in wirkt dies wie eine exakte Anleitung, ist aber in
              Wahrheit nur ein statistisch plausibles Muster.
            </li>

            <li>
              <strong
                >Fehlertyp 2: √úbersch√§tzung der eigenen F√§higkeiten.</strong
              >
              Teilweise suggerierte das LLM, es k√∂nne fertige, produktionsreife
              Minified-Bundles oder ZIP-Dateien f√ºr komplexe Bibliotheken
              ‚Äûerzeugen‚Äú, obwohl dies technisch nicht m√∂glich ist, da der
              Zugriff auf echte Build-Artefakte und externe Paketquellen fehlt.
              Hier zeigt sich eine systemische Tendenz zur √úberoptimierung:
              lieber eine scheinbar hilfreiche Antwort als ein klares ‚Äûgeht
              nicht‚Äú.
            </li>

            <li>
              <strong
                >Fehlertyp 3: Unklare Trennung von Konzept und
                Umsetzung.</strong
              >
              Konzeptionell richtige Schritte (z.&nbsp;B. ‚Äûlade Sigma.js lokal
              und binde sie statt √ºber CDN ein‚Äú) wurden mit konkreten
              Implementierungsdetails vermischt, die in der Realit√§t nicht
              √ºberpr√ºft waren. Dadurch verschob sich das Problem von der
              richtigen Idee hin zur falschen technischen Ausf√ºhrung.
            </li>

            <li>
              <strong>Lerneffekt f√ºr die Nutzung des LLM:</strong>
              <ul>
                <li>
                  Nutzer:innen sollten bei konkreten URLs, Pfaden oder
                  Paketnamen immer einen ‚ÄûRealit√§tscheck‚Äú einplanen und die
                  Links direkt testen.
                </li>
                <li>
                  Es ist sinnvoll, das LLM explizit darauf hinzuweisen, dass
                  Verweise auf externe Ressourcen nur als Vorschl√§ge zu
                  verstehen sind, nicht als garantierte Wahrheiten.
                </li>
                <li>
                  Prompts, die nach ‚Äûexakten Download-Links‚Äú oder ‚Äûfertigen
                  Minified-Bundles‚Äú fragen, sollten eher in Richtung ‚Äûbeschreibe
                  mir den Weg‚Äú umformuliert werden, nicht ‚Äûliefere mir die
                  konkrete Datei‚Äú.
                </li>
              </ul>
            </li>

            <li>
              <strong>Lerneffekt f√ºr das Modell (Meta-Perspektive):</strong>
              Dieser Eintrag macht sichtbar, dass LLMs zwar komplexe Workflows,
              Debugging-Strategien und Konzeptdesign sehr gut unterst√ºtzen
              k√∂nnen, aber an der Schnittstelle zur ‚Äûrealen Infrastruktur‚Äú
              (Netzwerk, CDNs, Dateisysteme, Build-Prozesse) schnell an Grenzen
              sto√üen. Der produktive Umgang damit besteht darin, diese Grenzen
              im Prompting mitzudenken und das Modell eher als
              <em>Erkl√§r- und Strukturierungspartner</em> denn als verl√§ssliche
              ‚ÄûDownload-Quelle‚Äú zu betrachten.
            </li>
          </ul>

          <p>
            Insgesamt zeigt dieser Eintrag, dass Prompt Engineering auch
            bedeutet, die systematischen Schw√§chen des LLM zu kennen: Es kann
            √ºberzeugend klingen, ohne recht zu haben. Gerade in technischen
            Kontexten sind Validierungsschritte, Tests und eine kritische
            Haltung gegen√ºber zu ‚Äûglatten‚Äú Antworten zentraler Bestandteil eines
            verantwortungsvollen Einsatzes.
          </p>
        </section>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation vom 19. November 2025
          ein Prompt Engineering Tagebuch mit den wichtigsten Inhalten,
          Fortschritten und Erkenntnissen zusammenstellen? Mach es bitte nach
          diesem Muster:<br /><br />

          [HTML-Muster eingef√ºgt]
        </p>

        <!-- ========================================= -->
    <!-- Eintrag 25 ‚Äì GEXF-Parsing -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 25 ‚Äì GEXF-Parsing, Attributmapping & Sigma-Kompatibilit√§t</h3>
      <p>
        Ein zentrales Thema des heutigen Arbeitstages war die Integration der
        Gephi-exportierten <code>rhizom_gephi.gexf</code>-Datei in die Webvisualisierung
        mit Sigma.js. Es zeigte sich, dass die Attributstruktur des GEXF nicht
        unmittelbar kompatibel mit Sigma war. Das LLM analysierte die Struktur,
        korrigierte ung√ºltige Attributnamen (insbesondere das problematische Attribut
        <code>type</code>) und identifizierte den Grund daf√ºr, dass Nodes nach dem
        Rendern grau erschienen oder gar nicht angezeigt wurden.
      </p>
      <ul>
        <li><strong>Ziel:</strong> GEXF-Daten vollst√§ndig und Sigma-konform laden</li>
        <li><strong>Prompt-Typ:</strong> Struktur-Analyse, Code-Korrektur</li>
        <li><strong>Ergebnis:</strong> Vollst√§ndige Parsing-Pipeline f√ºr alle Attribute</li>
        <li><strong>Erkenntnis:</strong> Sigma.js kollabiert bei bestimmten Attributnamen</li>
      </ul>
    </section>

    <!-- ========================================= -->
    <!-- Eintrag 26 ‚Äì Farbgebung -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 26 ‚Äì Farbgebung, Palette-Erweiterung & Multi-Nationalit√§ten</h3>
      <p>
        Ein weiterer Schwerpunkt war das Design einer stabilen Farblogik f√ºr das RHIZOM-Netzwerk.
        Die zuvor verwendeten Farbsets f√ºhrten zu Konflikten, Dopplungen oder grauen Knoten.
        Durch Erweiterung der Palette und automatische Zerlegung mehrteiliger Nationalit√§ten
        entstand eine robuste Farbcodierung.
      </p>
      <ul>
        <li><strong>Ziel:</strong> Unterschiedliche Farben f√ºr alle Nationalit√§ten</li>
        <li><strong>Prompt-Typ:</strong> Design-Refactoring, Debugging</li>
        <li><strong>Ergebnis:</strong> Konsistente Farblegende, korrekte Filter</li>
        <li><strong>Erkenntnis:</strong> Farblogik muss sich an echten Daten orientieren</li>
      </ul>
    </section>

    <!-- ========================================= -->
    <!-- Eintrag 27 ‚Äì Filterlogik -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 27 ‚Äì Filterlogik, Undo, Clear & UI-Erweiterungen</h3>
      <p>
        Die Weboberfl√§che bekam zahlreiche neue interaktive Elemente: Suchfeld, Filter,
        Undo- und Clear-Funktion, kompakte Legendenbox und saubere Zustandsverwaltung.
      </p>
      <ul>
        <li><strong>Ziel:</strong> Intuitive, explorative Netzwerkanalyse</strong></li>
        <li><strong>Prompt-Typ:</strong> UI/UX-Prompts, State-Management</li>
        <li><strong>Ergebnis:</strong> Reaktionsschnelle Filter & Undo</li>
        <li><strong>Erkenntnis:</strong> Kleine, zielgenaue Prompts verhindern Chaos</li>
      </ul>
    </section>

    <!-- ========================================= -->
    <!-- Eintrag 28 ‚Äì Node Shapes -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 28 ‚Äì Node-Shapes, Quadrate & Stabilit√§tsprobleme</h3>
      <p>
        Die Umstellung der Projektnodes auf quadratische Form f√ºhrte zu unerwarteten
        Rendering-Effekten: ‚Äûalles grau‚Äú oder vollst√§ndige Farblastung. Durch genaue
        Analyse der Rendering-Pipeline wurde klar, dass Custom-Programme die
        Farblogik √ºberschreiben, wenn sie zu fr√ºh aktiviert werden.
      </p>
      <ul>
        <li><strong>Ziel:</strong> Quadratische Projektnodes ohne Farbst√∂rungen</li>
        <li><strong>Prompt-Typ:</strong> JavaScript-Debugging</li>
        <li><strong>Ergebnis:</strong> Stabile Darstellung aller Node-Shapes</li>
        <li><strong>Erkenntnis:</strong> Reihenfolge der Attribute ist entscheidend</li>
      </ul>
    </section>

    <!-- ========================================= -->
    <!-- Eintrag 29 ‚Äì Label-Dichte -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 29 ‚Äì Label-Dichte, Zoom & visuelle Kontrolle</h3>
      <p>
        Die Label-Dichte verhielt sich zun√§chst fehlerhaft, da ein nicht existierendes
        Sigma-Setting verwendet wurde. Durch Austausch von
        <code>labelDensity</code> gegen <code>labelGridCellSize</code> konnte die
        Funktion pr√§zise gesteuert werden.
      </p>
      <ul>
        <li><strong>Ziel:</strong> Kontrolle √ºber Anzeigedichte</li>
        <li><strong>Prompt-Typ:</strong> API-Analyse</li>
        <li><strong>Ergebnis:</strong> Funktionierender Label-Slider</li>
        <li><strong>Erkenntnis:</strong> Dokumentation lesen lohnt sich</li>
      </ul>
    </section>

    <!-- ========================================= -->
    <!-- Eintrag 30 ‚Äì ForceAtlas2 -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 30 ‚Äì ForceAtlas2: Start/Stop & der ‚Äûleere Platzhalter‚Äú</h3>
      <p>
        Im Verlauf stellte sich heraus, dass der ForceAtlas2-Button wirkungslos war,
        weil kein echter Algorithmus eingebunden war. Stattdessen war ein
        Platzhalter vorhanden, der lediglich eine Warnung ausgab. Dadurch konnte das
        Layout nicht funktionieren.
      </p>
      <ul>
        <li><strong>Ziel:</strong> Dynamische Layout-Engine aktivieren</li>
        <li><strong>Prompt-Typ:</strong> Diagnose-Prompt</li>
        <li><strong>Ergebnis:</strong> Klare Identifikation des Problemursprungs</li>
        <li><strong>Erkenntnis:</strong> Manche Probleme sind Design, keine Bugs</li>
      </ul>
    </section>

    <!-- ========================================= -->
    <!-- Eintrag 31 ‚Äì Skalierung -->
    <!-- ========================================= -->

    <section class="entry">
      <h3>Eintrag 31 ‚Äì Skalierung des Prompting-Workflows & wachsende Systemkomplexit√§t</h3>
      <p>
        Der heutige Tag zeigte besonders deutlich, wie komplex Prompt Engineering
        wird, wenn Datenformate, Visualisierungslogik, Bibliotheken, HTML-Struktur
        und UI-Komponenten gleichzeitig betroffen sind. Die iterative Zusammenarbeit
        zwischen Nutzer:in und LLM entwickelte sich zu einem skalierbaren
        Entwicklungsworkflow, bei dem jeder Schritt auf dem vorherigen aufbaut.
      </p>
      <ul>
        <li>
          <strong>Ziel:</strong> Umgang mit Komplexit√§t ohne Kontrollverlust
        </li>
        <li>
          <strong>Prompt-Typ:</strong> Meta-Prompting, Refactoring, Strategiekombination
        </li>
        <li>
          <strong>Ergebnis:</strong> Ein stabiler, erweiterbarer JavaScript-Code,
          robuste Attributlogik, UI-Koh√§renz und klar strukturierte Fehleranalyse
        </li>
        <li>
          <strong>Erkenntnis:</strong> Effektives Prompt Engineering ist eine
          Kombination aus Kontextpflege, Modularisierung und Feedbackschleifen ‚Äî
          √§hnlich einem agilen Softwareentwicklungsprozess
        </li>
      </ul>
      <p>
        Damit wurde ein weiterer wichtiger Schritt hin zu einem vollst√§ndigen,
        visuellen Forschungsinstrument erreicht, das sowohl technisch stabil als
        auch analytisch nutzbar ist.
      </p>
    </section>

    <p class="intro-note">
          Und bitte noch einen letzten Eintrag mit einer Reflexion.
        </p>

    <section class="entry">
  <h3>Eintrag 32 ‚Äì Abschlie√üende Reflexion: Prompt Engineering als kollaborativer Erkenntnisprozess</h3>

  <p>
    Der heutige Tag war ein intensives Beispiel f√ºr die Tiefe und Breite, die
    Prompt Engineering inzwischen abdecken kann. Von Datenkonvertierung √ºber
    Webvisualisierung, Debugging, Farblogik, UI-Design, Attribut-Mapping,
    algorithmische Prozesse (ForceAtlas2) bis hin zu Meta-√úberlegungen √ºber die
    Arbeitsweise von LLMs selbst: Der Workflow zeigte, dass Prompting nicht nur
    Werkzeug, sondern integraler Bestandteil eines kreativen und technischen
    Forschungsprozesses ist.
  </p>

  <p>
    Besonders deutlich wurde, dass komplexe Systeme ‚Äì wie dein interaktiver
    Netzwerkgraph ‚Äì nicht durch einen einzigen ‚Äûperfekten Prompt‚Äú entstehen,
    sondern durch hunderte kleine, iterative Entscheidungen. Jeder Prompt wurde
    zu einem Baustein, der die vorherigen erg√§nzt, korrigiert, erweitert oder
    neu ausrichtet. Dieser dialogische Prozess erwies sich als genauso wichtig
    wie der Code selbst.
  </p>

  <ul>
    <li>
      <strong>1. Prompt Engineering erzeugt Struktur, nicht nur Antworten.</strong><br>
      Der Tag zeigte, dass LLM-Prompts dabei helfen, Komplexit√§t zu ordnen:
      Datenmodelle, UI-Elemente, Farblogiken, Analysefunktionen und
      Datenvisualisierung wurden durch den Prompt-Dialog strukturiert und
      operationalisiert.
    </li>

    <li>
      <strong>2. Fehler sind kein St√∂rfaktor, sondern ein integraler Bestandteil.</strong><br>
      Missverst√§ndnisse (z. B. ‚Äûalles grau‚Äú, fehlende Shapes, API-Fehler,
      Platzhalter-Algorithmen) f√ºhrten zu besseren L√∂sungen, weil sie neue
      Einsichten erzeugten ‚Äì √ºber Sigma.js, √ºber Datenstrukturen, √ºber Workflows
      und √ºber die Grenzen von LLM-Vorschl√§gen.
    </li>

    <li>
      <strong>3. Die Zusammenarbeit zwischen Mensch und KI ist ein wechselseitiger Prozess.</strong><br>
      Du hast die Daten, die Intention, den Kontext und die Qualit√§tskontrolle.
      Das Modell liefert Muster, Vorschl√§ge, Debugging, Struktur und
      Alternativen. Erst durch die Kombination entsteht etwas funktionierendes.
    </li>

    <li>
      <strong>4. Prompt Engineering ist ein wissenschaftlicher Prozess.</strong><br>
      Die heutige Arbeit glich einem Laborbetrieb: Hypothesen aufstellen,
      testen, falsifizieren, verfeinern, integrieren. Die Visualisierung wurde
      dadurch nicht nur technisch, sondern analytisch wertvoll.
    </li>

    <li>
      <strong>5. Transparenz und Dokumentation sind essenziell.</strong><br>
      Das Prompt Engineering Tagebuch selbst zeigt, wie wichtig
      Selbstreflexion, Nachvollziehbarkeit und bewusste Steuerung eines
      LLM-Dialogs f√ºr hochwertige Ergebnisse sind.
    </li>
  </ul>

  <p>
    Insgesamt demonstriert dieser letzte Eintrag, dass Prompt Engineering l√§ngst
    mehr ist als ‚ÄûTexteingabe‚Äú: Es ist ein Prozess des Mitdenkens,
    R√ºckfragens, Pr√ºfens und gemeinsamen Gestaltens. Genau darin liegt die
    eigentliche St√§rke ‚Äì nicht nur im fertigen Graphen, sondern im Weg dorthin.
  </p>
</section>

<p class="intro-note">
          GPT, kannst du mir alles, wor√ºber wir heute diskutiert haben, in sortierten Eintr√§gen nach diesem Muster zusammenfassen? Setze dabei bitte nach dem bisher letzten Eintrag deine neuen Eintr√§ge nach demselben Muster fort:<br /><br />

          [HTML-Muster eingef√ºgt]
        </p>

<section class="entry">
  <h3>Eintrag 33 ‚Äì HTML-Formatierung & Infobox-Erstellung</h3>
  <p>
    Der Arbeitstag begann mit der Aufgabe, textbasierte Aufgabenstellungen
    (1-Pager, Pitch-Konzept etc.) direkt in HTML zu √ºberf√ºhren. Besonderes
    Augenmerk lag darauf, die Vorgaben in ein Webformat einzubetten, sodass sie
    problemlos in GitHub Pages integriert werden k√∂nnen. Das LLM √ºbernahm die
    komplette Transformation in sauberes, gut lesbares HTML.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Formatierung komplexer Aufgabenbl√∂cke als HTML</li>
    <li><strong>Prompt-Typ:</strong> Transformations-Prompt (‚ÄûBitte in HTML‚Äú)</li>
    <li><strong>Ergebnis:</strong> Vollst√§ndig formatierte HTML-Bl√∂cke f√ºr Aufgaben</li>
    <li><strong>Erkenntnis:</strong> Klare Vorgaben √ºber Schriftgr√∂√üe, Box-Stil 
      und Layout verbessern die Konsistenz neuer Webkomponenten erheblich</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 34 ‚Äì Entwicklung einer Info-Box mit kleiner Typografie</h3>
  <p>
    Anschlie√üend wurde der Wunsch formuliert, die zuvor erzeugte HTML-Aufgabe in
    eine dezente Infobox zu integrieren. Das LLM schlug verschiedene Varianten vor ‚Äì
    Nutzung bestehender Klassen wie <code>.note-box</code> oder Erstellung einer
    neuen, spezielleren Klasse <code>.info-box-small</code>.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Einbettung von Aufgabenbl√∂cken in stilistische Info-Boxen</li>
    <li><strong>Prompt-Typ:</strong> Layout-/Stil-Prompt</li>
    <li><strong>Ergebnis:</strong> Fertige HTML- und CSS-Snippets zur sofortigen Integration</li>
    <li><strong>Erkenntnis:</strong> Web-Komponenten sollten modular entwickelt 
      werden: kleine Boxen, klare Typografie, einheitliche Margins</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 35 ‚Äì Glossar-Integration, automatische Verlinkung & ID-Management</h3>
  <p>
    Der n√§chste Schritt betraf das Glossar: Begriffe wie ‚Äûrhizomatische Strukturen‚Äú 
    sollten automatisch erkannt und verlinkt werden. Das LLM analysierte die 
    bestehende <code>glossar-linker.js</code> und integrierte neue Begriffe, IDs 
    sowie Backlink-Mechanismen.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Erweiterung des Glossars um neue Begriffe + Automatik-Links</li>
    <li><strong>Prompt-Typ:</strong> JS-Analyse & Mikropatching</li>
    <li><strong>Ergebnis:</strong> Korrekt sortierte Glossar-Eintr√§ge & funktionsf√§hige Backlinks</li>
    <li><strong>Erkenntnis:</strong> Selbst kleine Ungenauigkeiten im ID-Format 
      (Gro√ü-/Kleinschreibung, Bindestriche) verhindern automatische Verlinkung</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 36 ‚Äì Backlink-Script, Timing-Logik & UX-Optimierung</h3>
  <p>
    Bei der Implementierung der Backlinks (‚ÄûZur√ºck zur Textstelle‚Äú) wurde ein 
    komplexeres Verhalten notwendig: Backlinks sollten nur erscheinen, wenn die 
    Seite √ºber einen Glossar-Link ge√∂ffnet wird, und ansonsten verborgen bleiben.
    Das LLM entwickelte daf√ºr ein optimiertes JS-Snippet.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Kontextabh√§ngige Backlinks ohne St√∂reffekte</li>
    <li><strong>Prompt-Typ:</strong> UX-Prompt + Script-Optimierung</li>
    <li><strong>Ergebnis:</strong> Pr√§zises Backlink-Verhalten basierend auf URL-Parametern</li>
    <li><strong>Erkenntnis:</strong> UX-Skripte ben√∂tigen klare Triggersignale 
      (z. B. <code>?from=xyz</code>), um st√∂rfreie Bedingungen zu schaffen</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 37 ‚Äì Fu√ünoten-Hervorhebung, CSS-Debugging & Timing-Probleme</h3>
  <p>
    Es folgte eine l√§ngere Debugging-Phase rund um die blaue Hervorhebung von 
    Fu√ünoten. Das Problem: Hervorhebungen blieben bestehen oder verschwanden 
    gar nicht. Das LLM entwickelte ein neues Modell: Statt CSS <code>:target</code> 
    wurde eine JS-Klasse <code>.fn-highlight</code> eingef√ºhrt, die nach einem 
    Timeout automatisch entfernt wird.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Kurzzeitige, klare Hervorhebung der angesprungenen Fu√ünote</li>
    <li><strong>Prompt-Typ:</strong> CSS/JS-Debugging (‚ÄûWarum bleibt es blau?‚Äú)</li>
    <li><strong>Ergebnis:</strong> Stabiles Highlighting mit sauberem Timeout</li>
    <li><strong>Erkenntnis:</strong> <code>:target</code>-basiertes Styling ist 
      f√ºr dynamische Systeme oft unzuverl√§ssig; JS-gesteuerte Klassen sind robuster</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 38 ‚Äì Analyse der CSS-Konflikte & Neuaufbau der Highlight-Sektion</h3>
  <p>
    Die Hervorhebung funktionierte zun√§chst nicht, weil die bestehende CSS-Datei 
    alte, konkurrierende Regeln enthielt. Das LLM analysierte die komplette Datei, 
    identifizierte Konflikte und baute die gesamte Highlight-Sektion neu ‚Äì 
    inklusive geschmeidigem Fade-out.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Saubere CSS-Basis ohne subtil konkurrierende Regeln</li>
    <li><strong>Prompt-Typ:</strong> Vollanalyse einer externen CSS-Datei</li>
    <li><strong>Ergebnis:</strong> Neu geschriebenes, fehlerfreies Highlight-CSS</li>
    <li><strong>Erkenntnis:</strong> CSS-Konflikte entstehen oft durch alte 
      Regeln, die nicht mehr gebraucht werden ‚Äì Refactoring ist essenziell</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 39 ‚Äì Debugging der Fu√ünoten-Nummerierung & Hash-Logik</h3>
  <p>
    Ein weiteres Problem betraf die automatische Renummerierung der Fu√ünoten: 
    Manuelle Beispiele wie <code>[28]</code> verwiesen sp√§ter auf falsche Ziele 
    (<code>[29]</code>). Das LLM entwickelte ein zweistufiges System: automatische 
    Nummerierung aller <code>sup.fn</code>-Links + Korrektur aller manuellen Beispiele.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Stabile, konfliktfreie Fu√ünoten-Nummerierung</li>
    <li><strong>Prompt-Typ:</strong> Logik-Analyse & JS-Patching</li>
    <li><strong>Ergebnis:</strong> Konsistente Synchronisierung von Verweisen und IDs</li>
    <li><strong>Erkenntnis:</strong> Nummerierungslogik muss global gedacht werden ‚Äì 
      einzelne Abk√ºrzungen f√ºhren schnell zu Inkonsistenzen</li>
  </ul>
</section>


<section class="entry">
  <h3>Eintrag 40 ‚Äì Abschlie√üende Meta-Reflexion: Fu√ünoten, Glossar, JS & Systemkoh√§renz</h3>
  <p>
    Der Abschluss der heutigen Arbeit machte deutlich, dass scheinbar kleine 
    Web-Komponenten wie Fu√ünoten, Glossar-Links oder Backlinks komplexe 
    Systeme mit vielen Abh√§ngigkeiten sind. Das LLM half, aus Chaos ein 
    konsistentes, vollst√§ndig integriertes System zu formen.
  </p>
  <ul>
    <li><strong>Hauptthema:</strong> Systemische Koh√§renz statt Einzelkorrekturen</li>
    <li><strong>Reflexion:</strong> 
      Fu√ünotenhighlight, automatische Nummerierung, Backlinks, Glossar-Links und 
      Tooltip-Interaktionen greifen ineinander ‚Äì nur ein holistischer Ansatz 
      verhindert Fehlerketten.
    </li>
    <li><strong>Kern-Erkenntnis:</strong> 
      Effektives Prompt Engineering ist nicht ‚ÄûFrage‚ÄìAntwort‚Äú, sondern ein 
      kontinuierlicher, systemischer Designprozess.
    </li>
    <li><strong>Outcome:</strong> Ein vollst√§ndig funktionierendes, dynamisches 
      Web-√ñkosystem f√ºr wissenschaftliche Hypertext-Arbeit.</li>
  </ul>
</section>


        <!-- INFO/HELP-->
        <div class="note-box">
          Neue Eintr√§ge hinzuf√ºgen: <code>&lt;section class="entry"&gt;</code>
        </div>

        <p><a href="../index.html">‚Üê Zur√ºck zur Startseite</a></p>
      </article>
    </main>

    <!-- Footer -->
    <footer>
      <p>
        ¬© 2025 Rhizom-Projekt |
        <a href="https://github.com/gitti-huber/agki-pm-rhizom"
          >GitHub Repository</a
        >
      </p>
    </footer>

    <script>
      // Datum automatisch setzen (lokalisiert)
      document.getElementById("today").textContent =
        new Date().toLocaleDateString("de-AT", {
          year: "numeric",
          month: "long",
          day: "numeric",
        });
    </script>

    <a href="#top" class="back-to-top">‚Üë</a>
    <script>
      document.addEventListener("scroll", () => {
        if (window.scrollY > 200) {
          document.body.classList.add("scrolled");
        } else {
          document.body.classList.remove("scrolled");
        }
      });
    </script>

    <script src="../assets/js/glossar-linker.js"></script>
  </body>
</html>
