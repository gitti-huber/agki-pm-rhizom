<!doctype html>
<html lang="de">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Prompt Engineering Tagebuch</title>
  <link rel="stylesheet" href="../assets/css/styles.css">
  <style>
    .entry {
      border-left: 3px solid var(--accent);
      padding-left: 1rem;
      margin-bottom: 1.5rem;
    }

    .entry h3 {
      margin-top: 0;
    }
  </style>
</head>

<body>
  <header data-date="30. Oktober 2025" data-url="https://[username].github.io/agki-pm-rhizom/prompts/">
    <h1>Prompt Engineering Tagebuch</h1>
    <p class="subtitle">Versuche, Experimente & Reflexionen zur Arbeit mit LLMs</p>
    <nav>
      <a href="../index.html">Home</a>
      <a href="../about.html">Über das Projekt</a>
      <a href="../posts/index.html">Forschungsblog</a>
      <span aria-current="page">Prompt Engineering Tagebuch</span>
    </nav>
  </header>

  <main>
    <article>
      <p class="meta">Stand: <span id="today"></span> • <span class="pill">Prompt Engineering Tagebuch</span></p>

      <p class="intro-note">
        GPT, kannst du mir bitte aus dieser Konversation vom 30. Oktober 2025
        ein Prompt Engineering Tagebuch mit den wichtigsten Inhalten, Fortschritten
        und Erkenntnissen zusammenstellen? Mach es bitte nach diesem Muster:<br><br>

        [HTML-Muster eingefügt]
      </p>


      <section class="entry">
        <h3>Eintrag 1 – Strukturierung des Projekts & Setup</h3>
        <p>Zu Beginn stand die technische und methodische Vorbereitung im Vordergrund. Gemeinsam mit dem LLM wurden die
          Anforderungen für GitHub, VS Code, Obsidian und Python Schritt für Schritt umgesetzt, um eine stabile
          Arbeitsumgebung für das Forschungsprojekt <em>„Rhizomatische Strukturen im Kulturbereich“</em> zu schaffen.
        </p>
        <ul>
          <li><strong>Ziel:</strong> Einrichtung einer vollständigen Projektstruktur für Datenerhebung, Analyse und
            Dokumentation</li>
          <li><strong>Prompt-Typ:</strong> Schritt-für-Schritt-Anleitung mit iterativen Rückfragen</li>
          <li><strong>Ergebnis:</strong> Vollständiges Setup (GitHub, GitHub Pages, VS Code, Obsidian, Python)
            funktionierte nach Anleitung</li>
          <li><strong>Erkenntnis:</strong> Präzise, sequentielle Prompts mit klaren Zwischenschritten verhindern
            technische Fehler und Überforderung</li>
        </ul>
      </section>

      <section class="entry">
        <h3>Eintrag 2 – Datengrundlage & methodische Konzeptualisierung</h3>
        <p>Im Dialog wurde das Forschungsvorhaben zur Erfassung rhizomatischer Strukturen im Kulturbereich inhaltlich
          und methodisch geschärft.
          Das LLM half, die komplexe Beschreibung in eine klar strukturierte Forschungslogik zu überführen.</p>
        <ul>
          <li><strong>Ziel:</strong> Ableitung einer logischen, datenbasierten Forschungsstruktur aus heterogenen
            Textdaten</li>
          <li><strong>Prompt-Typ:</strong> Analytical prompting (Strukturierung, Zusammenfassung, Reorganisation)</li>
          <li><strong>Ergebnis:</strong> Klare Trennung von Datenbasis, Forschungskontext, Fragestellung, Methodik und
            Output</li>
          <li><strong>Erkenntnis:</strong> Gute Prompts entstehen, wenn das LLM nicht nur auf Inhalte, sondern auf
            <em>Beziehungen</em> zwischen Datenebenen fokussiert wird
          </li>
        </ul>
      </section>

      <section class="entry">
        <h3>Eintrag 3 – Webseitenstruktur & Designfeinabstimmung</h3>
        <p>Im weiteren Verlauf diente das LLM als Entwicklungs- und Designpartner bei der Umsetzung der GitHub Pages.
          Dabei ging es um Navigation, CSS-Design, Farb- und Typografiefragen sowie Druckansicht.
          Durch iteratives Prompting konnten inkrementelle Änderungen getestet und validiert werden.</p>
        <ul>
          <li><strong>Ziel:</strong> Einheitliches, druckfreundliches Layout mit professionellem, aber zurückhaltendem
            Stil</li>
          <li><strong>Prompt-Typ:</strong> Iterative Code-Refinement-Prompts („Mach es dezenter, aber professioneller“)
          </li>
          <li><strong>Ergebnis:</strong> Einheitliches Design aller Seiten; Navigation und Druckansicht harmonisiert
          </li>
          <li><strong>Erkenntnis:</strong> Kleinere, kontextbezogene Prompts („Behalte alles, ändere nur Farben“)
            liefern stabilere Resultate als große Neuschreibungen</li>
        </ul>
      </section>

      <section class="entry">
        <h3>Eintrag 4 – Fehleranalyse & Debugging mit dem LLM</h3>
        <p>Mehrfach traten kleinere Probleme mit GitHub Desktop, Zeilenenden, CSS-Abständen und relativen Links auf.
          Durch gezieltes Nachfragen und schrittweise Fehlersuche im Prompt-Dialog ließen sich die Probleme effizient
          lösen.</p>
        <ul>
          <li><strong>Ziel:</strong> Fehlersuche durch dialogische Zusammenarbeit (Codeinterpretation durch LLM)</li>
          <li><strong>Prompt-Typ:</strong> „Explain and fix“-Prompts mit konkreten Fehlermeldungen</li>
          <li><strong>Ergebnis:</strong> Korrekte Navigation, funktionierende Druckansicht, konsistente Styles</li>
          <li><strong>Erkenntnis:</strong> Debugging gelingt am besten, wenn Prompts Kontext (Dateipfade, Fehlermeldung,
            gewünschtes Verhalten) explizit enthalten</li>
        </ul>
      </section>

      <section class="entry">
        <h3>Eintrag 5 – Prompt-Reflexion</h3>
        <p>Die Zusammenarbeit mit dem LLM zeigte, dass technisches Prompting (Syntax, Fehlerbehebung) und
          konzeptionelles Prompting (Struktur, Argumentation) unterschiedliche Strategien erfordern.
          Während technische Prompts präzise und schrittweise formuliert sein müssen, profitieren konzeptuelle Prompts
          von Offenheit und Kontextbezug.</p>
        <ul>
          <li><strong>Gute Strategien:</strong> Iteration, Kontext-Erhalt, kleine Anpassungen pro Prompt</li>
          <li><strong>Herausforderungen:</strong> Zu viele Änderungen auf einmal; unklare Begrenzung des Aufgabenfokus
          </li>
          <li><strong>Lerneffekt:</strong> Effektives Prompting ist eine Art „Dialogdesign“ – es braucht Rhythmus,
            Präzision und Geduld</li>
        </ul>
      </section>

      <p class="intro-note">
        GPT, kannst du mir bitte aus dieser Konversation von heute (16. November 2025) ein Prompt Engineering Tagebuch
        mit den wichtigsten Inhalten, Fortschritten und Erkenntnissen zusammenstellen? Mach es bitte nach diesem Muster
        und setze dabei die Liste der Einträge fort::<br><br>

        [HTML-Liste der bisherigen Einträge 1–5 eingefügt]<br><br>
      </p>

      <section class="entry">
        <h3>Eintrag 6 – Erstellung einer thematischen Basisbibliographie</h3>
        <p>Der Arbeitstag begann mit der Bitte um eine Bibliographie zum Thema „Kultur und Digitalisierung“. Das LLM
          übernahm die Rolle eines Recherche- und Strukturierungspartners und half, aus einem breiten, unspezifizierten
          Themenfeld eine verwertbare, akademische Literaturliste zu generieren.</p>
        <ul>
          <li><strong>Ziel:</strong> Erstellung einer kuratierten Basisbibliographie für kleine Kulturinstitutionen,
            Museen und Vereine</li>
          <li><strong>Prompt-Typ:</strong> Literatur-Generierung mit thematischer Fokussierung</li>
          <li><strong>Ergebnis:</strong> Relevante Kernliteratur zu Digitalisierung, Kulturbetrieb und digitalen
            Strategien wurde zusammengestellt</li>
          <li><strong>Erkenntnis:</strong> Die Präzisierung „kleine Museen / Kulturvereine“ erhöhte die Relevanz der
            Literaturqualität deutlich</li>
        </ul>
      </section>
      <section class="entry">
        <h3>Eintrag 7 – Erweiterung der Bibliographie um LLM- und KI-Aspekte</h3>
        <p>Die Literaturliste wurde anschließend um KI-, LLM- und Digitalisierungsthemen erweitert. Ziel war, die
          Verbindung zwischen aktuellen Sprachmodellen, Digitalisierungsprozessen und Kulturerbe-Kontexten sichtbar zu
          machen.</p>
        <ul>
          <li><strong>Ziel:</strong> Abbildung der Schnittstelle zwischen Künstlicher Intelligenz, LLMs und digitalen
            Kulturdaten</li>
          <li><strong>Prompt-Typ:</strong> Ergänzungs-Prompt („Gibt es auch etwas zu LLMs?“)</li>
          <li><strong>Ergebnis:</strong> Einbindung neuer Literatur zu KI-gestützten Kulturerbesystemen, Knowledge
            Graphs und automatisierter Datenanalyse</li>
          <li><strong>Erkenntnis:</strong> Kleine, offene Ergänzungsfragen ermöglichen dem LLM flexible inhaltliche
            Erweiterungen ohne Stilbruch</li>
        </ul>
      </section>
      <section class="entry">
        <h3>Eintrag 8 – Import & Normalisierung heterogener Literaturdaten</h3>
        <p>Ein komplexer Abschnitt bestand darin, eine große, unsortierte Liste verschiedenster Medienformate (PDF, URL,
          EPUB, LNK) in ein sauberes Literaturformat zu überführen. Das LLM fungierte hier als „Parsing-Agent“ und
          normalisierte unstrukturierte Dateinamen zu vollständigen Literaturangaben.</p>
        <ul>
          <li><strong>Ziel:</strong> Vereinheitlichung hunderter Literaturangaben in APA-ähnliche Form</li>
          <li><strong>Prompt-Typ:</strong> „Extract & Normalize“-Prompting (Datenextraktion aus Dateinamen)</li>
          <li><strong>Ergebnis:</strong> Erzeugung einer alphabetisch sortierten, medienübergreifenden
            Literaturübersicht</li>
          <li><strong>Erkenntnis:</strong> Das LLM benötigt klare Regeln („Option B – strikte Dateinamen-Übernahme“), um
            nicht zu viel zu „erraten“</li>
        </ul>
      </section>
      <section class="entry">
        <h3>Eintrag 9 – Transformation großer Literaturlisten in HTML</h3>
        <p>Die umfangreiche Literatur wurde in ein HTML-konformes Format überführt, um direkt in eine wissenschaftliche
          Webseite integriert zu werden. Die Aufgabe bestand aus Formatierung, Listenstrukturierung und der Korrektur
          von HTML-Syntaxfehlern.</p>
        <ul>
          <li><strong>Ziel:</strong> Automatisierte Web-Integration einer komplexen Bibliographie</li>
          <li><strong>Prompt-Typ:</strong> Code-Transformation und Formatierungs-Prompt</li>
          <li><strong>Ergebnis:</strong> Vollständig in HTML konvertierte, sauber strukturierte Literaturblöcke</li>
          <li><strong>Erkenntnis:</strong> Das LLM ist besonders effektiv, wenn der Ziel-HTML-Block klar vorgegeben wird
          </li>
        </ul>
      </section>
      <section class="entry">
        <h3>Eintrag 10 – Typografie & CSS-Optimierung des Literaturverzeichnisses</h3>
        <p>Ein zentraler Teil des Dialogs drehte sich um typografisch saubere APA-Darstellung: kleinere Schrift,
          korrektes Hanging-Indent und automatische Numerierung. Mehrere Iterationen führten zu einer stabilen,
          kompakten Darstellung.</p>
        <ul>
          <li><strong>Ziel:</strong> Professionelle, automatisierte APA-Darstellung in HTML/CSS</li>
          <li><strong>Prompt-Typ:</strong> Code-Refinement / Micro-Prompts („etwas kleiner“, „mehr Abstand“)</li>
          <li><strong>Ergebnis:</strong> Vollautomatische APA-Nummerierung mit CSS-Counter, konsistentem Hanging-Indent
          </li>
          <li><strong>Erkenntnis:</strong> Kleine CSS-Prompts mit klaren Variablen („Schrift kleiner, aber lesbar“)
            liefern zuverlässig präzise Ergebnisse</li>
        </ul>
      </section>
      <section class="entry">
        <h3>Eintrag 11 – Fehlerkorrektur: doppelte Nummerierung & Styling-Konflikte</h3>
        <p>Ein technisches Problem entstand durch doppelte Nummerierung: manuelle Werte wie <code>[01]</code>
          kollidierten mit der automatischen CSS-Zählung. Durch Debugging im Dialog wurden die Konflikte aufgelöst.</p>
        <ul>
          <li><strong>Ziel:</strong> Entfernen der doppelten Nummerierung und Sicherstellung funktionierender
            Fußnoten-Links</li>
          <li><strong>Prompt-Typ:</strong> Debugging-Prompt („Wo muss ich das einfügen?“)</li>
          <li><strong>Ergebnis:</strong> Bereinigte Liste, automatische Nummerierung, funktionierende IDs für Fußnoten
          </li>
          <li><strong>Erkenntnis:</strong> Bei HTML+CSS muss das LLM klare Angaben erhalten, welcher Block übrig bleiben
            soll – sonst entstehen Überschreibungsfehler</li>
        </ul>
      </section>
      <section class="entry">
        <h3>Eintrag 12 – Finalisierung und typografische Feinjustierung</h3>
        <p>Zum Abschluss wurden Schriftgröße, Zeilenabstand und Einzüge weiter optimiert. Das LLM passte die
          Literaturtypografie an wissenschaftliche Standards an, ohne die Lesbarkeit auf der Webseite zu
          beeinträchtigen.</p>
        <ul>
          <li><strong>Ziel:</strong> Erstellung einer minimalistisch-kompakten, wissenschaftlich korrekten
            Literaturliste</li>
          <li><strong>Prompt-Typ:</strong> Feintuning-Prompt („Ja, bitte etwas kleiner“)</li>
          <li><strong>Ergebnis:</strong> Stabile Endversion der APA-Darstellung mit CSS-Counter, dünnerem Zeilenabstand
            und kompakter Einrückung</li>
          <li><strong>Erkenntnis:</strong> Visuelles Feintuning gelingt am besten, wenn man schrittweise konkretisiert
            („noch kleiner“, „noch enger“ statt „mach schöner“)</li>
        </ul>
      </section>

            <p class="intro-note">
        Erst auf Aufforderung, eine Prompt-Reflexion nach dem Muster von Eintrag 5 zu ergänzen:
      </p>

      <section class="entry">
  <h3>Eintrag 13 – Gesamtreflexion: Prompting als Arbeitsmethode</h3>
  <p>Der gesamte Verlauf der Zusammenarbeit zeigt sehr klar, dass Prompting nicht bloß ein technisches Werkzeug ist, 
     sondern eine eigenständige Arbeitsmethode, die Struktur, Präzision und dialogische Klarheit erfordert. 
     Über alle Einträge hinweg – von Setup und Dateistruktur über Datenvisualisierung, Literaturlisten, CSS-Feinjustierung,
     Debugging und Webdesign – wurde deutlich, dass gutes Prompting weniger von formaler Komplexität 
     als von sauberem Kontextmanagement und iterativer Kommunikation abhängt.</p>

  <ul>
    <li><strong>Kontextpflege als Schlüssel:</strong> Effektive Ergebnisse entstanden immer dann, wenn frühere Schritte,
        getroffene Entscheidungen und relevante Codeausschnitte bewusst im Prompt gehalten oder wiederholend erklärt wurden.
        Das LLM arbeitet optimal, wenn es an eine kontinuierliche argumentative Linie anknüpfen kann.</li>

    <li><strong>Kleine Schritte statt große Sprünge:</strong> In fast allen technischen Aufgaben (HTML-Listen, automatische APA-Nummerierung,
        CSS-Refactoring, Druckansicht, Hanging-Indent, Typografie) zeigte sich, dass kleine, klar isolierte Anweisungen bessere Ergebnisse liefern 
        als umfassende Neuformulierungen. Iteration schlägt Komplettanweisungen.</li>

    <li><strong>Explizite Fokussierung:</strong> Das LLM reagiert stabiler, wenn der Aufgabenfokus eng gesetzt wird 
        („nur Schriftgröße ändern“, „Nummern automatisch, keine manuelle Nummerierung“, 
        „behalte alles außer dem Abstand“). Dadurch werden Nebeneffekte, Stilüberschneidungen 
        oder Überinterpretationen vermieden.</li>

    <li><strong>Verständnis von Beziehungen zwischen Komponenten:</strong> Besonders bei Webdesign und CSS half das LLM am besten,
        wenn die Prompts nicht nur Beschreibungen einzelner Elemente enthielten, 
        sondern die Beziehungen zwischen Selektoren, Stilregeln und HTML-Struktur benannten.
        Prompting funktioniert als „Systemdenken in Sprache“.</li>

    <li><strong>Reflexion verbessert das Prompting:</strong> Mehrere Einträge zeigten, dass die Qualität der Ergebnisse steigt,
        wenn der Prompt explizit begründet, warum eine Änderung vorgenommen wird
        („weil Schrift zu groß“, „weil doppelte Nummerierung“, „weil Abstand unruhig wirkt“).
        Diese Meta-Kommunikation erleichtert dem LLM, die gewünschte Richtung zu verstehen.</li>

    <li><strong>Prompting als kollaborative Wissensarbeit:</strong> Die gesamte Arbeit bestätigt,
        dass LLM-Interaktion in Forschungsprojekten nicht als Werkzeugbedienung,
        sondern als kollaborativer, iterativer Denkprozess funktioniert.
        Strukturierung, Dekontextualisierung, Umformatierung und Designentscheidungen 
        entstehen im wechselseitigen Dialog – Prompting wird damit selbst zu einer
        epistemischen Praxis des Projekts.</li>
  </ul>

  <p>Insgesamt zeigt der gesamte Prompt-Verlauf dieses Projekttages, dass erfolgreiches Prompting nicht nur
     genaue Befehle produziert, sondern Denk-, Struktur- und Entscheidungsprozesse stabilisiert.
     Das LLM wird damit zum methodischen Partner, dessen Potenzial sich erst durch dialogische Führung voll entfaltet.</p>
</section>


      <p class="meta">Neue Einträge hinzufügen: <code>&lt;section class="entry"&gt;</code></p>
    </article>
  </main>

  <footer>
    <p>© 2025 Rhizom-Projekt | <a href="https://github.com/gitti-huber/agki-pm-rhizom">GitHub Repository</a></p>
  </footer>

  <script>
    document.getElementById('today').textContent =
      new Date().toLocaleDateString('de-AT', { year: 'numeric', month: 'long', day: 'numeric' });
  </script>
</body>

</html>