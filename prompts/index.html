<!DOCTYPE html>
<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Prompt Engineering Tagebuch</title>
    <link rel="stylesheet" href="../assets/css/styles.css" />
    <style>
      .entry {
        border-left: 3px solid var(--accent);
        padding-left: 1rem;
        margin-bottom: 1.5rem;
      }

      .entry h3 {
        margin-top: 0;
      }
    </style>
  </head>

  <body>
    <a id="top"></a>
    <header
      data-date="30. Oktober 2025"
      data-url="https://[username].github.io/agki-pm-rhizom/prompts/"
    >
      <h1>Prompt Engineering Tagebuch</h1>
      <p class="subtitle">
        Versuche, Experimente & Reflexionen zur Arbeit mit LLMs
      </p>
      <nav>
        <a href="../index.html">Home</a>
        <a href="../about.html">Über das Projekt</a>
        <a href="../posts/index.html">Forschungsblog</a>
        <span aria-current="page">Prompt Engineering Tagebuch</span>
      </nav>
    </header>

    <main>
      <article>
        <p class="meta">
          Stand: <span id="today"></span> •
          <span class="pill">Prompt Engineering Tagebuch</span>
        </p>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation vom 30. Oktober 2025
          ein Prompt Engineering Tagebuch mit den wichtigsten Inhalten,
          Fortschritten und Erkenntnissen zusammenstellen? Mach es bitte nach
          diesem Muster:<br /><br />

          [HTML-Muster eingefügt]
        </p>

        <section class="entry">
          <h3>Eintrag 1 – Strukturierung des Projekts & Setup</h3>
          <p>
            Zu Beginn stand die technische und methodische Vorbereitung im
            Vordergrund. Gemeinsam mit dem LLM wurden die Anforderungen für
            GitHub, VS Code, Obsidian und Python Schritt für Schritt umgesetzt,
            um eine stabile Arbeitsumgebung für das Forschungsprojekt
            <em>„Rhizomatische Strukturen im Kulturbereich“</em> zu schaffen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Einrichtung einer vollständigen
              Projektstruktur für Datenerhebung, Analyse und Dokumentation
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Schritt-für-Schritt-Anleitung mit
              iterativen Rückfragen
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollständiges Setup (GitHub, GitHub
              Pages, VS Code, Obsidian, Python) funktionierte nach Anleitung
            </li>
            <li>
              <strong>Erkenntnis:</strong> Präzise, sequentielle Prompts mit
              klaren Zwischenschritten verhindern technische Fehler und
              Überforderung
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 2 – Datengrundlage & methodische Konzeptualisierung</h3>
          <p>
            Im Dialog wurde das Forschungsvorhaben zur Erfassung rhizomatischer
            Strukturen im Kulturbereich inhaltlich und methodisch geschärft. Das
            LLM half, die komplexe Beschreibung in eine klar strukturierte
            Forschungslogik zu überführen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Ableitung einer logischen, datenbasierten
              Forschungsstruktur aus heterogenen Textdaten
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Analytical prompting (Strukturierung,
              Zusammenfassung, Reorganisation)
            </li>
            <li>
              <strong>Ergebnis:</strong> Klare Trennung von Datenbasis,
              Forschungskontext, Fragestellung, Methodik und Output
            </li>
            <li>
              <strong>Erkenntnis:</strong> Gute Prompts entstehen, wenn das LLM
              nicht nur auf Inhalte, sondern auf <em>Beziehungen</em> zwischen
              Datenebenen fokussiert wird
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 3 – Webseitenstruktur & Designfeinabstimmung</h3>
          <p>
            Im weiteren Verlauf diente das LLM als Entwicklungs- und
            Designpartner bei der Umsetzung der GitHub Pages. Dabei ging es um
            Navigation, CSS-Design, Farb- und Typografiefragen sowie
            Druckansicht. Durch iteratives Prompting konnten inkrementelle
            Änderungen getestet und validiert werden.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Einheitliches, druckfreundliches Layout mit
              professionellem, aber zurückhaltendem Stil
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Iterative Code-Refinement-Prompts
              („Mach es dezenter, aber professioneller“)
            </li>
            <li>
              <strong>Ergebnis:</strong> Einheitliches Design aller Seiten;
              Navigation und Druckansicht harmonisiert
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleinere, kontextbezogene Prompts
              („Behalte alles, ändere nur Farben“) liefern stabilere Resultate
              als große Neuschreibungen
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 4 – Fehleranalyse & Debugging mit dem LLM</h3>
          <p>
            Mehrfach traten kleinere Probleme mit GitHub Desktop, Zeilenenden,
            CSS-Abständen und relativen Links auf. Durch gezieltes Nachfragen
            und schrittweise Fehlersuche im Prompt-Dialog ließen sich die
            Probleme effizient lösen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Fehlersuche durch dialogische
              Zusammenarbeit (Codeinterpretation durch LLM)
            </li>
            <li>
              <strong>Prompt-Typ:</strong> „Explain and fix“-Prompts mit
              konkreten Fehlermeldungen
            </li>
            <li>
              <strong>Ergebnis:</strong> Korrekte Navigation, funktionierende
              Druckansicht, konsistente Styles
            </li>
            <li>
              <strong>Erkenntnis:</strong> Debugging gelingt am besten, wenn
              Prompts Kontext (Dateipfade, Fehlermeldung, gewünschtes Verhalten)
              explizit enthalten
            </li>
          </ul>
        </section>

        <section class="entry">
          <h3>Eintrag 5 – Prompt-Reflexion</h3>
          <p>
            Die Zusammenarbeit mit dem LLM zeigte, dass technisches Prompting
            (Syntax, Fehlerbehebung) und konzeptionelles Prompting (Struktur,
            Argumentation) unterschiedliche Strategien erfordern. Während
            technische Prompts präzise und schrittweise formuliert sein müssen,
            profitieren konzeptuelle Prompts von Offenheit und Kontextbezug.
          </p>
          <ul>
            <li>
              <strong>Gute Strategien:</strong> Iteration, Kontext-Erhalt,
              kleine Anpassungen pro Prompt
            </li>
            <li>
              <strong>Herausforderungen:</strong> Zu viele Änderungen auf
              einmal; unklare Begrenzung des Aufgabenfokus
            </li>
            <li>
              <strong>Lerneffekt:</strong> Effektives Prompting ist eine Art
              „Dialogdesign“ – es braucht Rhythmus, Präzision und Geduld
            </li>
          </ul>
        </section>

        <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation von heute (15.
          November 2025) ein Prompt Engineering Tagebuch mit den wichtigsten
          Inhalten, Fortschritten und Erkenntnissen zusammenstellen? Mach es
          bitte nach diesem Muster und setze dabei die Liste der Einträge
          fort:<br /><br />

          [HTML-Liste der bisherigen Einträge 1–5 eingefügt]<br /><br />
        </p>

        <section class="entry">
          <h3>Eintrag 6 – Erstellung einer thematischen Basisbibliographie</h3>
          <p>
            Der Arbeitstag begann mit der Bitte um eine Bibliographie zum Thema
            „Kultur und Digitalisierung“. Das LLM übernahm die Rolle eines
            Recherche- und Strukturierungspartners und half, aus einem breiten,
            unspezifizierten Themenfeld eine verwertbare, akademische
            Literaturliste zu generieren.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Erstellung einer kuratierten
              Basisbibliographie für kleine Kulturinstitutionen, Museen und
              Vereine
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Literatur-Generierung mit
              thematischer Fokussierung
            </li>
            <li>
              <strong>Ergebnis:</strong> Relevante Kernliteratur zu
              Digitalisierung, Kulturbetrieb und digitalen Strategien wurde
              zusammengestellt
            </li>
            <li>
              <strong>Erkenntnis:</strong> Die Präzisierung „kleine Museen /
              Kulturvereine“ erhöhte die Relevanz der Literaturqualität deutlich
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 7 – Erweiterung der Bibliographie um LLM- und KI-Aspekte
          </h3>
          <p>
            Die Literaturliste wurde anschließend um KI-, LLM- und
            Digitalisierungsthemen erweitert. Ziel war, die Verbindung zwischen
            aktuellen Sprachmodellen, Digitalisierungsprozessen und
            Kulturerbe-Kontexten sichtbar zu machen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Abbildung der Schnittstelle zwischen
              Künstlicher Intelligenz, LLMs und digitalen Kulturdaten
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Ergänzungs-Prompt („Gibt es auch
              etwas zu LLMs?“)
            </li>
            <li>
              <strong>Ergebnis:</strong> Einbindung neuer Literatur zu
              KI-gestützten Kulturerbesystemen, Knowledge Graphs und
              automatisierter Datenanalyse
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleine, offene Ergänzungsfragen
              ermöglichen dem LLM flexible inhaltliche Erweiterungen ohne
              Stilbruch
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 8 – Import & Normalisierung heterogener Literaturdaten
          </h3>
          <p>
            Ein komplexer Abschnitt bestand darin, eine große, unsortierte Liste
            verschiedenster Medienformate (PDF, URL, EPUB, LNK) in ein sauberes
            Literaturformat zu überführen. Das LLM fungierte hier als
            „Parsing-Agent“ und normalisierte unstrukturierte Dateinamen zu
            vollständigen Literaturangaben.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Vereinheitlichung hunderter
              Literaturangaben in APA-ähnliche Form
            </li>
            <li>
              <strong>Prompt-Typ:</strong> „Extract & Normalize“-Prompting
              (Datenextraktion aus Dateinamen)
            </li>
            <li>
              <strong>Ergebnis:</strong> Erzeugung einer alphabetisch
              sortierten, medienübergreifenden Literaturübersicht
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM benötigt klare Regeln
              („Option B – strikte Dateinamen-Übernahme“), um nicht zu viel zu
              „erraten“
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>Eintrag 9 – Transformation großer Literaturlisten in HTML</h3>
          <p>
            Die umfangreiche Literatur wurde in ein HTML-konformes Format
            überführt, um direkt in eine wissenschaftliche Webseite integriert
            zu werden. Die Aufgabe bestand aus Formatierung,
            Listenstrukturierung und der Korrektur von HTML-Syntaxfehlern.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Automatisierte Web-Integration einer
              komplexen Bibliographie
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Code-Transformation und
              Formatierungs-Prompt
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollständig in HTML konvertierte,
              sauber strukturierte Literaturblöcke
            </li>
            <li>
              <strong>Erkenntnis:</strong> Das LLM ist besonders effektiv, wenn
              der Ziel-HTML-Block klar vorgegeben wird
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 10 – Typografie & CSS-Optimierung des
            Literaturverzeichnisses
          </h3>
          <p>
            Ein zentraler Teil des Dialogs drehte sich um typografisch saubere
            APA-Darstellung: kleinere Schrift, korrektes Hanging-Indent und
            automatische Numerierung. Mehrere Iterationen führten zu einer
            stabilen, kompakten Darstellung.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Professionelle, automatisierte
              APA-Darstellung in HTML/CSS
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Code-Refinement / Micro-Prompts
              („etwas kleiner“, „mehr Abstand“)
            </li>
            <li>
              <strong>Ergebnis:</strong> Vollautomatische APA-Nummerierung mit
              CSS-Counter, konsistentem Hanging-Indent
            </li>
            <li>
              <strong>Erkenntnis:</strong> Kleine CSS-Prompts mit klaren
              Variablen („Schrift kleiner, aber lesbar“) liefern zuverlässig
              präzise Ergebnisse
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>
            Eintrag 11 – Fehlerkorrektur: doppelte Nummerierung &
            Styling-Konflikte
          </h3>
          <p>
            Ein technisches Problem entstand durch doppelte Nummerierung:
            manuelle Werte wie <code>[01]</code> kollidierten mit der
            automatischen CSS-Zählung. Durch Debugging im Dialog wurden die
            Konflikte aufgelöst.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Entfernen der doppelten Nummerierung und
              Sicherstellung funktionierender Fußnoten-Links
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Debugging-Prompt („Wo muss ich das
              einfügen?“)
            </li>
            <li>
              <strong>Ergebnis:</strong> Bereinigte Liste, automatische
              Nummerierung, funktionierende IDs für Fußnoten
            </li>
            <li>
              <strong>Erkenntnis:</strong> Bei HTML+CSS muss das LLM klare
              Angaben erhalten, welcher Block übrig bleiben soll – sonst
              entstehen Überschreibungsfehler
            </li>
          </ul>
        </section>
        <section class="entry">
          <h3>Eintrag 12 – Finalisierung und typografische Feinjustierung</h3>
          <p>
            Zum Abschluss wurden Schriftgröße, Zeilenabstand und Einzüge weiter
            optimiert. Das LLM passte die Literaturtypografie an
            wissenschaftliche Standards an, ohne die Lesbarkeit auf der Webseite
            zu beeinträchtigen.
          </p>
          <ul>
            <li>
              <strong>Ziel:</strong> Erstellung einer minimalistisch-kompakten,
              wissenschaftlich korrekten Literaturliste
            </li>
            <li>
              <strong>Prompt-Typ:</strong> Feintuning-Prompt („Ja, bitte etwas
              kleiner“)
            </li>
            <li>
              <strong>Ergebnis:</strong> Stabile Endversion der APA-Darstellung
              mit CSS-Counter, dünnerem Zeilenabstand und kompakter Einrückung
            </li>
            <li>
              <strong>Erkenntnis:</strong> Visuelles Feintuning gelingt am
              besten, wenn man schrittweise konkretisiert („noch kleiner“, „noch
              enger“ statt „mach schöner“)
            </li>
          </ul>
        </section>

        <p class="intro-note">
          Erst auf Aufforderung, eine Prompt-Reflexion nach dem Muster von
          Eintrag 5 zu ergänzen:
        </p>

        <section class="entry">
          <h3>Eintrag 13 – Gesamtreflexion: Prompting als Arbeitsmethode</h3>
          <p>
            Der gesamte Verlauf der Zusammenarbeit zeigt sehr klar, dass
            Prompting nicht bloß ein technisches Werkzeug ist, sondern eine
            eigenständige Arbeitsmethode, die Struktur, Präzision und
            dialogische Klarheit erfordert. Über alle Einträge hinweg – von
            Setup und Dateistruktur über Datenvisualisierung, Literaturlisten,
            CSS-Feinjustierung, Debugging und Webdesign – wurde deutlich, dass
            gutes Prompting weniger von formaler Komplexität als von sauberem
            Kontextmanagement und iterativer Kommunikation abhängt.
          </p>

          <ul>
            <li>
              <strong>Kontextpflege als Schlüssel:</strong> Effektive Ergebnisse
              entstanden immer dann, wenn frühere Schritte, getroffene
              Entscheidungen und relevante Codeausschnitte bewusst im Prompt
              gehalten oder wiederholend erklärt wurden. Das LLM arbeitet
              optimal, wenn es an eine kontinuierliche argumentative Linie
              anknüpfen kann.
            </li>

            <li>
              <strong>Kleine Schritte statt große Sprünge:</strong> In fast
              allen technischen Aufgaben (HTML-Listen, automatische
              APA-Nummerierung, CSS-Refactoring, Druckansicht, Hanging-Indent,
              Typografie) zeigte sich, dass kleine, klar isolierte Anweisungen
              bessere Ergebnisse liefern als umfassende Neuformulierungen.
              Iteration schlägt Komplettanweisungen.
            </li>

            <li>
              <strong>Explizite Fokussierung:</strong> Das LLM reagiert
              stabiler, wenn der Aufgabenfokus eng gesetzt wird („nur
              Schriftgröße ändern“, „Nummern automatisch, keine manuelle
              Nummerierung“, „behalte alles außer dem Abstand“). Dadurch werden
              Nebeneffekte, Stilüberschneidungen oder Überinterpretationen
              vermieden.
            </li>

            <li>
              <strong>Verständnis von Beziehungen zwischen Komponenten:</strong>
              Besonders bei Webdesign und CSS half das LLM am besten, wenn die
              Prompts nicht nur Beschreibungen einzelner Elemente enthielten,
              sondern die Beziehungen zwischen Selektoren, Stilregeln und
              HTML-Struktur benannten. Prompting funktioniert als „Systemdenken
              in Sprache“.
            </li>

            <li>
              <strong>Reflexion verbessert das Prompting:</strong> Mehrere
              Einträge zeigten, dass die Qualität der Ergebnisse steigt, wenn
              der Prompt explizit begründet, warum eine Änderung vorgenommen
              wird („weil Schrift zu groß“, „weil doppelte Nummerierung“, „weil
              Abstand unruhig wirkt“). Diese Meta-Kommunikation erleichtert dem
              LLM, die gewünschte Richtung zu verstehen.
            </li>

            <li>
              <strong>Prompting als kollaborative Wissensarbeit:</strong> Die
              gesamte Arbeit bestätigt, dass LLM-Interaktion in
              Forschungsprojekten nicht als Werkzeugbedienung, sondern als
              kollaborativer, iterativer Denkprozess funktioniert.
              Strukturierung, Dekontextualisierung, Umformatierung und
              Designentscheidungen entstehen im wechselseitigen Dialog –
              Prompting wird damit selbst zu einer epistemischen Praxis des
              Projekts.
            </li>
          </ul>

          <p>
            Insgesamt zeigt der gesamte Prompt-Verlauf dieses Projekttages, dass
            erfolgreiches Prompting nicht nur genaue Befehle produziert, sondern
            Denk-, Struktur- und Entscheidungsprozesse stabilisiert. Das LLM
            wird damit zum methodischen Partner, dessen Potenzial sich erst
            durch dialogische Führung voll entfaltet.
          </p>
        </section>

         <p class="intro-note">
          GPT, kannst du mir bitte aus dieser Konversation von heute (16.
          November 2025) ein Prompt Engineering Tagebuch mit den wichtigsten
          Inhalten, Fortschritten und Erkenntnissen zusammenstellen? Mach es
          bitte nach diesem Muster und setze dabei die Liste der Einträge
          fort:<br /><br />

          [HTML-Liste der bisherigen Einträge eingefügt]<br /><br />
        </p>

        <!-- ================================================ -->
<!-- PROMPT ENGINEERING TAGEBUCH – EINTRÄGE ab 14    -->
<!-- ================================================ -->

<section class="entry">
  <h3>Eintrag 14 – HTML-Integration & strukturelle Anpassungen</h3>
  <p>
    Der Arbeitstag begann mit mehreren Iterationen rund um die Startseite,
    die About-Seite und die Einbindung von Bildern. Das LLM wurde eingesetzt,
    um HTML-Blöcke umzuschreiben, redundante Inhalte zu reorganisieren und
    Navigationselemente konsistenter zu gestalten.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Straffe, klare Startseite + Verlagerung längerer Texte in „About“</li>
    <li><strong>Prompt-Typ:</strong> Strukturierungs-Prompts („Bitte komplett neu formulieren“)</li>
    <li><strong>Ergebnis:</strong> Modularere Seitenstruktur; Startseite mit kurzem Intro und Bild</li>
    <li><strong>Erkenntnis:</strong> Bei HTML-Reorganisation ist es entscheidend, dem LLM die Dateipfade und die gewünschte Positionierung exakt zu nennen</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 15 – Linkstruktur, relative Pfade & Navigationsfehler</h3>
  <p>
    Mehrere Prompts betrafen fehlerhafte Links
    (<code>./index.html</code> vs. <code>../index.html</code>) sowie
    die Frage, wie korrekt zwischen Ordnern navigiert wird.
    Durch Schritt-für-Schritt-Debugging konnte die Navigation stabilisiert werden.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Fehlerfreie relative Links zwischen <code>/posts/</code> und Root-Verzeichnis</li>
    <li><strong>Prompt-Typ:</strong> „Explain & fix“-Prompts zur Pfadkorrektur</li>
    <li><strong>Ergebnis:</strong> Alle internen Links funktionieren unabhängig vom Ordnerkontext</li>
    <li><strong>Erkenntnis:</strong> Das LLM kann nur korrekte Pfade generieren, wenn die exakte Ordnerstruktur im Prompt mitformuliert wird</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 16 – CSS-Klassen, Bilddarstellung & responsive Design</h3>
  <p>
    Ein Schwerpunkt war die Frage, warum Bilder nicht angezeigt wurden.
    Über mehrere Anläufe wurde geklärt, dass die verwendete Klasse
    <code>.hero-image</code> nicht existierte und stattdessen
    <code>.image</code> genutzt werden musste.
    Gleichzeitig wurde demonstriert, wie man Bilder kleiner, zentriert oder
    mit Captions (<code>&lt;figcaption&gt;</code>) einbindet.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Konsistente Bilddarstellung in allen Blog-Einträgen</li>
    <li><strong>Prompt-Typ:</strong> CSS-Refinement-Prompts</li>
    <li><strong>Ergebnis:</strong> Einheitliche Klassenstruktur (<code>.image</code>, <code>.image.narrow</code>) und funktionierende Captions</li>
    <li><strong>Erkenntnis:</strong> Kleine CSS-Nachbesserungen durch das LLM funktionieren verlässlich, wenn HTML und CSS gemeinsam gezeigt werden</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 17 – JavaScript-Optimierung & Tooltip-Feinjustierung</h3>
  <p>
    Bei der Gestaltung der Fußnoten-Tooltips wurden mehrere kleinere
    Optimierungen vorgenommen: Bereinigung der Positionierungslogik,
    Sicherstellen, dass <code>scrollIntoView()</code> erst nach dem Öffnen von
    <code>&lt;details&gt;</code> läuft, sowie Vereinheitlichung der Hash-Navigation.
    Das LLM half, die Funktionsweise zu debuggen und zu erklären.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Stabiles, barrierearmes Fußnoten-System</li>
    <li><strong>Prompt-Typ:</strong> JS-Debugging-Prompts („Warum springt der Tooltip?“)</li>
    <li><strong>Ergebnis:</strong> Deutlich stabilere Interaktion mit Footnotes & Literaturverzeichnis</li>
    <li><strong>Erkenntnis:</strong> Das LLM benötigt beim Debuggen den gesamten JavaScript-Block, um Seiteneffekte korrekt einzuschätzen</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 18 – Vollintegration großer Textdateien (Modelltheorie)</h3>
  <p>
    Ein umfangreicher Abschnitt der Sitzung bestand darin,
    einen langen wissenschaftlichen Text (Stachowiaks Modelltheorie,
    Relation zum Datenmodell) in die Forschungsseite einzubetten.
    Das LLM übernahm die Aufgabe, den Text HTML-konform zu strukturieren,
    stilistisch in das bestehende Layout einzufügen
    und Kapitel logisch einzubinden („Netzwerkmodell Teil II“).
  </p>
  <ul>
    <li><strong>Ziel:</strong> Wissenschaftlichen Langtext harmonisch in das Weblayout integrieren</li>
    <li><strong>Prompt-Typ:</strong> Transformations-Prompts („Baue das unter Abschnitt X ein“)</li>
    <li><strong>Ergebnis:</strong> HTML-blöcke mit semantisch korrekten Überschriften, Listen und Absätzen</li>
    <li><strong>Erkenntnis:</strong> LLM-basierte Text-nach-HTML-Konvertierung gelingt besonders sauber, wenn die Zielstruktur (Kapitel, Unterkapitel) vorher festgelegt wird</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 19 – Datenbankschema, ER-Diagramm & Netzwerklogik</h3>
  <p>
    Ein zentraler Teil des Dialogs drehte sich um die tatsächliche Struktur
    der SQLite-Datenbank <code>rhizom.db</code>.
    Das LLM analysierte die Tabellen, stellte Referenzen her und formulierte
    einen präzisen Netzwerkaufbau: Nodes = Personen + Projekte,
    Edges = Beziehungen über Rollen und Zeit.
    Die Modelllogik wurde ausführlich in Text umgesetzt und korrekt an die
    reale Datenstruktur angepasst.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Korrekte Darstellung des realen Datenmodells anstelle früherer Platzhalter</li>
    <li><strong>Prompt-Typ:</strong> Analyse-Prompt („Schau dir die DB genau an!“)</li>
    <li><strong>Ergebnis:</strong> Vollständig überarbeiteter Abschnitt „Netzwerkmodell (Teil II)“</li>
    <li><strong>Erkenntnis:</strong> Je präziser die Datenquelle (hier: echte DB), desto zuverlässiger die Modellbeschreibung des LLM</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 20 – Einbettung von PDF-Material & Download-Links</h3>
  <p>
    Es wurde geklärt, wie interne Dateien – konkret <code>data/rhizom_text.pdf</code> –
    korrekt verlinkt werden. Das LLM stellte einfache, robuste HTML-Snippets bereit,
    um PDF-Downloads projektweit konsistent zu integrieren.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Korrekte Einbindung interner Downloads</li>
    <li><strong>Prompt-Typ:</strong> „Show me the snippet“-Prompt</li>
    <li><strong>Ergebnis:</strong> Sauberer Download-Link mit <code>target="_blank"</code></li>
    <li><strong>Erkenntnis:</strong> Das LLM liefert besonders stabile Ergebnisse, wenn der exakte Ordnerpfad vorgegeben wird</li>
  </ul>
</section>

<section class="entry">
  <h3>Eintrag 21 – Großes HTML-Refactoring & Zusammenführung mehrere Teilseiten</h3>
  <p>
    Am Ende wurden längere HTML-Passagen zusammengeführt:
    Netzwerkmodell, Modelltheorie, ER-Diagramm,
    visuelle Beispiele, Methodenabschnitte.
    Das LLM unterstützte beim Zusammenbau großer HTML-Dateien und stellte sicher,
    dass semantische Ebenen (<code>&lt;section&gt;</code>, <code>&lt;h2&gt;</code>,
    <code>&lt;article&gt;</code>) erhalten bleiben.
  </p>
  <ul>
    <li><strong>Ziel:</strong> Harmonisierung der gesamten Forschungsseite</li>
    <li><strong>Prompt-Typ:</strong> Großformatige „Integrations-Prompts“</li>
    <li><strong>Ergebnis:</strong> Konsistentes, logisches Dokument ohne doppelte Überschriften</li>
    <li><strong>Erkenntnis:</strong> Bei sehr langen HTML-Texten funktioniert das LLM am besten, wenn Schritt für Schritt integriert und nicht alles auf einmal umgewandelt wird</li>
  </ul>
</section>

<!-- ========================= -->
<!-- ABSCHLUSSREFLEXION       -->
<!-- ========================= -->

<section class="entry">
  <h3>Eintrag 22 – Reflexion: Prompting als Web-Entwicklungsworkflow</h3>
  <p>
    Der heutige Arbeitstag hat exemplarisch gezeigt, dass Prompting beim
    Web-Development eine hybride Arbeitsform darstellt:
    gleichzeitig analytisch, technisch und kuratorisch.
    HTML, CSS und JavaScript wurden nicht einfach generiert,
    sondern in dialogischen Iterationen verbessert.
  </p>

  <ul>
    <li>
      <strong>Iterationen als Designprinzip:</strong>
      Die besten Ergebnisse entstanden immer in kleinen Schritten:
      „Mach das Bild kleiner“, „Nur die Klasse ändern, sonst nichts“,
      „Behalte den gesamten Block, füge X ein“.
    </li>

    <li>
      <strong>Kontext entscheidet alles:</strong>
      Das LLM reagierte besonders stabil, wenn der gesamte HTML- oder CSS-Block
      gezeigt wurde, statt nur einzelne Zeilen.
    </li>

    <li>
      <strong>Prompting als kooperative Wissensarbeit:</strong>
      Komplexe Inhalte wie Datenbanken, wissenschaftliche Modelltheorie,
      Webdesign und Informationsarchitektur wurden im Wechselspiel zwischen
      Mensch und Modell erzeugt – nicht als „Antwort“, sondern als
      kontinuierliches Co-Entwerfen.
    </li>

    <li>
      <strong>Fehler als Teil des Workflows:</strong>
      Linkfehler, kaputte Bilder, ungeschlossene Tags – das Debugging war selbst
      ein Prompting-Prozess und wurde durch gemeinsame Fehlersuche effizient gelöst.
    </li>
  </ul>

  <p>
    Insgesamt zeigt der heutige Tag sehr klar: Prompt Engineering ist nicht nur
    Produktionsmittel, sondern Teil des Forschungs- und Entwicklungsprozesses –
    ein dialogischer Lernraum, der technische Umsetzung, konzeptionelle
    Klarheit und kontinuierliches Refactoring miteinander verbindet.
  </p>
</section>

        <!-- INFO/HELP-->
          <div class="note-box">
            Neue Einträge hinzufügen: <code>&lt;section class="entry"&gt;</code>
          </div>

        <p><a href="../index.html">← Zurück zur Startseite</a></p>
      </article>
    </main>

    <!-- Footer -->
    <footer>
      <p>
        © 2025 Rhizom-Projekt |
        <a href="https://github.com/gitti-huber/agki-pm-rhizom"
          >GitHub Repository</a
        >
      </p>
    </footer>

    <script>
      // Datum automatisch setzen (lokalisiert)
      document.getElementById("today").textContent =
        new Date().toLocaleDateString("de-AT", {
          year: "numeric",
          month: "long",
          day: "numeric",
        });
    </script>

    <a href="#top" class="back-to-top">↑</a>
    <script>
      document.addEventListener("scroll", () => {
        if (window.scrollY > 200) {
          document.body.classList.add("scrolled");
        } else {
          document.body.classList.remove("scrolled");
        }
      });
    </script>
  </body>
</html>
